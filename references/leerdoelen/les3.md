Read chapter 6, 8 and 9. This is not about RNNs, but about the training process in general.
It covers the training process (what we have been doing so far and will continue to do) and will give you a theoretical background on how the training process works and how to improve model performance, so in a sense all these chapters cover the more practical 3.15 from this lesson.
However, it also helps with previous learning goals like:
1.12, 2.8, 2.10 and it will also prepare you for 4.4, 4.5, 4.6

# Les 3
De student begrijpt:
3.1 - wat de motivatie is om RNNs te gebruiken
3.2 - wat een window en horizon zijn
3.3 - Wat belangrijk is bij datapreparatie om data leakage te voorkomen
3.4 - Hoe een simple RNN werkt (hidden state)
3.5 - Waarin een GRU en LSTM verschillen van RNN (gates)
3.6 - Wat de functies van een gate zijn (remember, forget, something in between)
3.7 - Hoe een gate werkt (met een hadamard product)
3.8 - wat de voor en nadelen van een LSTM vs GRU vs RNN zijn
3.9 - hoe windowing werkt bij timeseries, en waarom dat relevant is
3.10 - hoe 1D convolutions werken bij timeseries
3.11 - begrijpt hoe een naive model werkt en wat de motivatie hierachter is (MASE metric)

De student kan:
3.12 - passief de wiskunde van een RNN/GRU/LSTM volgen, inclusief de notatie
3.13 - Een dataset windowen
3.14 - Een configureerbare RNN bouwen
3.15 - Een timeseries model handmatig hypertunen en daar verslaglegging van doen.

# resources
1. https://youtu.be/LHXXI4-IEns?si=JOgsNKCohksH0Pdf
2. https://youtu.be/8HyCNIVRbSU?si=p8Su2AOJTRFFI5MK
3. https://youtu.be/YCzL96nL7j0?si=42IUk3lm2ZzCTaLV
4. https://youtu.be/WCUNPb-5EYI?si=lrHvh7-RsFthjjnD

Watch the first two videos.
The third video is from statsquest, if you like his style you can watch that one too.
The last video explains the concept in a different way. If it confuses you, stick to the first three,
but if you feel like a different perspective might help, watch the last one too.

The book doesnt cover RNNs, so all material comes from the lessons and the videos.
