{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will explore this dataset: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State#\n",
    "\n",
    "> All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 01:29:40.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datatools\u001b[0m:\u001b[36mget_file\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mFile /home/sarmad/.cache/mads_datasets/egg/EGG.arff already exists, skip download\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "from mads_datasets import datatools\n",
    "from pathlib import Path\n",
    "data_dir = Path.home() / \".cache/mads_datasets/egg\"\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True)\n",
    "\n",
    "filename = \"EGG.arff\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "datatools.get_file(data_dir=data_dir, filename=filename, url=url, unzip=False)\n",
    "datapath = data_dir / filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the arff file with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "data = arff.loadarff(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a tuple of a description and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tuple)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset: EEG_DATA\n",
       "\tAF3's type is numeric\n",
       "\tF7's type is numeric\n",
       "\tF3's type is numeric\n",
       "\tFC5's type is numeric\n",
       "\tT7's type is numeric\n",
       "\tP7's type is numeric\n",
       "\tO1's type is numeric\n",
       "\tO2's type is numeric\n",
       "\tP8's type is numeric\n",
       "\tT8's type is numeric\n",
       "\tFC6's type is numeric\n",
       "\tF4's type is numeric\n",
       "\tF8's type is numeric\n",
       "\tAF4's type is numeric\n",
       "\teyeDetection's type is nominal, range is ('0', '1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 15k observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14980"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations are tuples of floats and a byte as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.void((4329.23, 4009.23, 4289.23, 4148.21, 4350.26, 4586.15, 4096.92, 4641.03, 4222.05, 4238.46, 4211.28, 4280.51, 4635.9, 4393.85, b'0'), dtype=[('AF3', '<f8'), ('F7', '<f8'), ('F3', '<f8'), ('FC5', '<f8'), ('T7', '<f8'), ('P7', '<f8'), ('O1', '<f8'), ('O2', '<f8'), ('P8', '<f8'), ('T8', '<f8'), ('FC6', '<f8'), ('F4', '<f8'), ('F8', '<f8'), ('AF4', '<f8'), ('eyeDetection', 'S1')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.bytes_'>\n"
     ]
    }
   ],
   "source": [
    "for x in data[0][0]:\n",
    "    print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cast the byte ot int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for x in data[0]:\n",
    "    labels.append(int(x[14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4487983978638184)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 45% of the data has closed eyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises 1\n",
    "\n",
    "- download the data to a given path. You can use the datatools.py method get_file for that, and wrap it with the prerpocessing.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** the dataset is downloaded to the respective path folder.\n",
    "\n",
    "</font>\n",
    "\n",
    "- build a custom Dataset that yields a $X, y$ tuple of tensors. $X$ should be sequential in time. Remember: a dataset should implement `__get_item__` and `__len__`.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** A custom Dataset named `EEGEyeDataset` is defined to return the $X$ and $y$ when called by dataloader\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "- You can try to implement your own datafactory. Study all the examples in `mads_datasets` sourcecode.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** the custom datafactory is implemented by using `BaseDatastreamer` from the `mads_datasets` library.\n",
    "\n",
    "</font>\n",
    "\n",
    "- note that you could model this as both a classification task, but also as a sequence-to-sequence task! For this excercise, make it a classification task with consecutive 0s or 1s only.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** at first classification task is implemented by fixing the sequence length to 1.\n",
    "\n",
    "</font>\n",
    "\n",
    "- Note that, for a training task, a seq2seq model will probably be more realistic. However, the classification is a nice excercise because it is harder to set up.\n",
    "- figure out what the length distribution is of your dataset: how many timestamps do you have for every consecutive sequence of 0s and 1s? On average, median, min, max?\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** the provided dataset is from one time-series data for one time, hence there is no length distribution, for each time-stamp 14 values are noted for 0s and 1s as the output for close or open eyes at that moment.\n",
    "\n",
    "</font>\n",
    "\n",
    "- create a dataloader that yields timeseries with (batch, sequence_lenght). You can implement: windowed, padded and batched.\n",
    "    1. yielding a windowed item should be the easy level\n",
    "    2. yielding windowed and padded is medium level \n",
    "    3. yielding windowed, padded and batched is expert level, because the windowing will cause the timeseries to have different sizes. You will need to buffer before you can yield a batch.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** The dataloaders are implemented for all the levels. As discussed above that the dataset doesnot require any padding.\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "1. Upload this to github. \n",
    "2. Put your dev notebooks in a seperate folder\n",
    "3. Put all your functions in the src folder\n",
    "4. Use a formater & linter\n",
    "5. Add a single notebook, that sources the src folder. Indicate which level you got (1, 2 or 3)\n",
    "6. and that shows your dataloader works:\n",
    "    - it should not give errors because it runs out of data! Either let is stop by itself, or run forever.\n",
    "    - batchsize should be consistent (in case 1 and 2, batchsize is 1)\n",
    "    - sequence length is allowed to vary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Code added below**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(datapath, comment='@', header=None)  \n",
    "\n",
    "# Convert last column to target variable\n",
    "X_data = df.iloc[:, :-1].values\n",
    "y_data = df.iloc[:, -1].values.astype(int)\n",
    "\n",
    "# Normalize the values to make it easier for the model to learn\n",
    "scaler = StandardScaler()\n",
    "X_data = scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14980, 14), torch.Size([0]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# creating a custom dataset\n",
    "# this is done as it stores the dataset tensors and defines a sequence length for time-series extraction.\n",
    "class EEGEyeDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        features = features.reshape(-1, 1, features.shape[1])\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Dataloader for level 1**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Tuple\n",
    "\n",
    "class preprocess_level1:\n",
    "    def __call__(self, batch: List[Tuple]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        X, Y = zip(*batch)\n",
    "        return X, torch.stack(Y)\n",
    "\n",
    "dataset = EEGEyeDataset(X_data, y_data)\n",
    "dataloader_level1 = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=preprocess_level1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Dataloader for level 2 with padding**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess_level2:\n",
    "    def __call__(self, batch: List[Tuple]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        X, Y = zip(*batch)\n",
    "        X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        return X, torch.stack(Y)\n",
    "\n",
    "dataset = EEGEyeDataset(X_data, y_data)\n",
    "dataloader_level2 = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=preprocess_level2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Dataloader for level 3 wtih padding and sorted sequence**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class preprocess_level3:\n",
    "    def __call__(self, batch: List[Tuple]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "        X, Y = zip(*batch)\n",
    "        X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        return X, torch.stack(Y)\n",
    "\n",
    "dataset = EEGEyeDataset(X_data, y_data)\n",
    "dataloader_level3 = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=preprocess_level3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import gin\n",
    "\n",
    "# Custom LSTM model configurable with custom_models.gin file\n",
    "gin.enter_interactive_mode()\n",
    "@gin.configurable\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "\n",
    "dataset = EEGEyeDataset(X_data, y_data)\n",
    "\n",
    "# a datafactory is implemented just like 'mads_datasets'\n",
    "datastreamer = BaseDatastreamer(dataset, batchsize=64, preprocessor=preprocess_level3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 14]), torch.Size([64]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(datastreamer.stream()))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer.metrics import Metric\n",
    "import numpy as np\n",
    "Array = np.ndarray\n",
    "\n",
    "# a custom Accuracy metric is defined for classification task\n",
    "class AccuracySeqtoSeq(Metric):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Accuracy\"\n",
    "\n",
    "    def __call__(self, y: Array, yhat: Array) -> float:\n",
    "        yhat = np.argmax(yhat, axis=-1)\n",
    "        return (yhat == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes, metrics, Trainer, rnn_models\n",
    "from torch import optim\n",
    "\n",
    "# to load the .gin file\n",
    "gin.parse_config_file(\"custom_models.gin\")\n",
    "\n",
    "accuracy = AccuracySeqtoSeq()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # loss for classification\n",
    "log_dir = Path(\"modellogs/dummy\")\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(datastreamer),\n",
    "    valid_steps=len(datastreamer),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN,],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 00:48:43.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/dummy/20250223-004843\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 150.36it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.6897 test 0.6855 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 167.51it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6857 test 0.6817 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 116.68it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6820 test 0.6786 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 114.75it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.6800 test 0.6763 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 122.56it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.6758 test 0.6753 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 107.00it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 0.6749 test 0.6758 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 131.48it/s]\n",
      "\u001b[32m2025-02-23 00:48:43.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 0.6726 test 0.6773 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 140.09it/s]]\n",
      "\u001b[32m2025-02-23 00:48:43.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 0.6810 test 0.6773 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 128.31it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.6841 test 0.6763 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 65.02it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.6769 test 0.6753 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 56.95it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 0.6773 test 0.6749 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 60.34it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 0.6716 test 0.6749 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 122.65it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 0.6728 test 0.6750 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 115.89it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 0.6746 test 0.6750 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 151.97it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 0.6754 test 0.6750 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 114.45it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 0.6761 test 0.6749 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 130.00it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 0.6765 test 0.6746 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 162.80it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 0.6744 test 0.6742 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 138.82it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 0.6727 test 0.6737 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 103.83it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 0.6731 test 0.6731 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 84.94it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 0.6739 test 0.6725 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 94.62it/s]/s]\n",
      "\u001b[32m2025-02-23 00:48:44.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 0.6743 test 0.6718 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 115.28it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 0.6733 test 0.6711 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 139.49it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 0.6739 test 0.6701 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 111.43it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 0.6693 test 0.6690 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 108.29it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 0.6666 test 0.6675 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 117.61it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 0.6689 test 0.6657 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 111.84it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 0.6645 test 0.6634 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 128.27it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 0.6632 test 0.6607 metric ['0.5938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 112.39it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 0.6591 test 0.6574 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 128.47it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 0.6597 test 0.6539 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 145.67it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 0.6511 test 0.6502 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 123.63it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 32 train 0.6483 test 0.6473 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 152.91it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 33 train 0.6496 test 0.6461 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 138.41it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 34 train 0.6535 test 0.6464 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 136.61it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 35 train 0.6447 test 0.6462 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 138.02it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 36 train 0.6515 test 0.6439 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 156.11it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 37 train 0.6411 test 0.6409 metric ['0.5781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 145.43it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 38 train 0.6350 test 0.6382 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 127.18it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 39 train 0.6408 test 0.6356 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 137.59it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 40 train 0.6419 test 0.6336 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 133.93it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 41 train 0.6431 test 0.6331 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 180.09it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 42 train 0.6308 test 0.6323 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 187.61it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 43 train 0.6337 test 0.6309 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 122.43it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 44 train 0.6416 test 0.6294 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 115.46it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 45 train 0.6305 test 0.6279 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 132.12it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 46 train 0.6376 test 0.6266 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 154.04it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 47 train 0.6253 test 0.6253 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 148.47it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 48 train 0.6295 test 0.6247 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 134.66it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 49 train 0.6230 test 0.6247 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 124.40it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 50 train 0.6320 test 0.6248 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 130.23it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 51 train 0.6069 test 0.6260 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 135.27it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 52 train 0.6327 test 0.6259 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 139.78it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 53 train 0.6375 test 0.6237 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 153.14it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 54 train 0.6223 test 0.6231 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 146.37it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 55 train 0.6231 test 0.6226 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 139.17it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 56 train 0.6093 test 0.6221 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 142.60it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 57 train 0.6151 test 0.6212 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 123.24it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 58 train 0.6213 test 0.6203 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 121.89it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 59 train 0.6204 test 0.6203 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 118.52it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 60 train 0.6254 test 0.6199 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 128.82it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 61 train 0.6240 test 0.6192 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 148.44it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 62 train 0.6253 test 0.6192 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 48.24it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 63 train 0.6343 test 0.6194 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 111.25it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 64 train 0.6219 test 0.6193 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 104.39it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 65 train 0.6223 test 0.6188 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 120.85it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 66 train 0.6083 test 0.6177 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 139.59it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 67 train 0.6211 test 0.6177 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 141.77it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 68 train 0.6193 test 0.6181 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 143.69it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:44.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 69 train 0.6143 test 0.6181 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 138.59it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 70 train 0.6208 test 0.6164 metric ['0.6094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 136.03it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 71 train 0.6227 test 0.6154 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 133.22it/s]\n",
      "\u001b[32m2025-02-23 00:48:44.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 72 train 0.6190 test 0.6163 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 131.60it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 73 train 0.6180 test 0.6168 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 142.83it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 74 train 0.6208 test 0.6153 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 143.76it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 75 train 0.6107 test 0.6137 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 146.65it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 76 train 0.6065 test 0.6135 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 143.01it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:45.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 77 train 0.6207 test 0.6141 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 147.35it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 78 train 0.6137 test 0.6137 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 137.47it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 79 train 0.6033 test 0.6124 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 52.28it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 80 train 0.6112 test 0.6116 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 145.79it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 81 train 0.6189 test 0.6118 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 130.26it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 82 train 0.6199 test 0.6121 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 91.77it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 83 train 0.6126 test 0.6116 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 181.55it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:45.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 84 train 0.6004 test 0.6104 metric ['0.7031']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 129.25it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 85 train 0.6022 test 0.6100 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 132.87it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 86 train 0.6118 test 0.6108 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 129.89it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 87 train 0.6219 test 0.6099 metric ['0.6406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 156.65it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 88 train 0.6064 test 0.6089 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 158.03it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 89 train 0.6130 test 0.6086 metric ['0.6875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 115.73it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 90 train 0.6177 test 0.6086 metric ['0.6875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 130.91it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 91 train 0.6146 test 0.6085 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 128.42it/s]s]\n",
      "\u001b[32m2025-02-23 00:48:45.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 92 train 0.6042 test 0.6079 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 174.89it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 93 train 0.6098 test 0.6072 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 168.52it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 94 train 0.6037 test 0.6068 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 146.51it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 95 train 0.5962 test 0.6065 metric ['0.6719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 134.04it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 96 train 0.6204 test 0.6057 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 150.41it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 97 train 0.6091 test 0.6053 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 127.42it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 98 train 0.5960 test 0.6049 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1/1 [00:00<00:00, 172.88it/s]\n",
      "\u001b[32m2025-02-23 00:48:45.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 99 train 0.6165 test 0.6046 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 66.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# train on custom LSTM model\n",
    "model = LSTMModel()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=datastreamer.stream(),\n",
    "    validdataloader=datastreamer.stream(),\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device='cpu',\n",
    "    )\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2\n",
    "- build a Dataset that yields sequences of X, y. This time, y is a sequence and can contain both 0s and 1s\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** the Dataset is created to return the X and y, both being the sequence of lenght 10\n",
    "\n",
    "</font>\n",
    "\n",
    "- create a Dataloader with this\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** The dataloader streamer is defined by `BaseDatastreamer` from the `mads_datasets` library.\n",
    "\n",
    "</font>\n",
    "\n",
    "- Test appropriate architectures (RNN, Attention)\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** The `AttentionGRU` is trained for this sequence dataset. The parameters are defined in `custom_models.gin`. The final accuracy with this model is around 93%\n",
    "\n",
    "</font>\n",
    "\n",
    "- for the loss, note that you will need a BCELoss instead of a CrossEntroyLoss\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** `BCEWithLogitsLoss` is used as we are now working in seq 2 seq training and working with logits\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Code added below**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom dataset\n",
    "# this is done as it stores the dataset tensors and defines a sequence length for time-series extraction.\n",
    "class EEGEyeDataset2(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.sequence_length = 10\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx:idx + self.sequence_length]\n",
    "        y = self.labels[idx:idx + self.sequence_length]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "# CUSTOM defined preprocess to load the X and y\n",
    "class preprocess_dummy:\n",
    "    def __call__(self, batch: List[Tuple]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "        X, Y = zip(*batch)\n",
    "        X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        return X, torch.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGEyeDataset2(X_data, y_data)\n",
    "\n",
    "datastreamer = BaseDatastreamer(dataset, batchsize=64, preprocessor=preprocess_dummy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10, 14]), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(datastreamer.stream()))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer.metrics import Metric\n",
    "import numpy as np\n",
    "Array = np.ndarray\n",
    "\n",
    "# Accuracy metric is defined to work with binary probabilities\n",
    "class AccuracySeqtoSeq(Metric):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Accuracy\"\n",
    "\n",
    "    def __call__(self, y: Array, yhat: Array) -> float:\n",
    "        yhat = (yhat >= 0.5).astype(int)\n",
    "        return (yhat == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = AccuracySeqtoSeq()\n",
    "\n",
    "gin.parse_config_file(\"custom_models.gin\")\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()   # loss function for seq 2 seq\n",
    "log_dir = Path(\"modellogs/dummy\")\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(datastreamer),\n",
    "    valid_steps=len(datastreamer),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN,],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-23 02:35:50.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/dummy/20250223-023550\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/10 [00:00<?, ?it/s]100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 20.51it/s]\n",
      "\u001b[32m2025-02-23 02:36:05.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.6660 test 0.6512 metric ['0.5905']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 20.63it/s]\n",
      "\u001b[32m2025-02-23 02:36:20.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6425 test 0.6172 metric ['0.6158']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 21.02it/s]\n",
      "\u001b[32m2025-02-23 02:36:35.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6013 test 0.5503 metric ['0.6580']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 19.68it/s]\n",
      "\u001b[32m2025-02-23 02:36:50.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.5151 test 0.4956 metric ['0.7411']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 20.42it/s]\n",
      "\u001b[32m2025-02-23 02:37:05.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.4556 test 0.4053 metric ['0.8016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 19.85it/s]\n",
      "\u001b[32m2025-02-23 02:37:20.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 0.3834 test 0.3593 metric ['0.8338']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 20.67it/s]\n",
      "\u001b[32m2025-02-23 02:37:35.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 0.3288 test 0.2673 metric ['0.8689']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 19.97it/s]\n",
      "\u001b[32m2025-02-23 02:37:51.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 0.2705 test 0.2540 metric ['0.8875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 20.17it/s]\n",
      "\u001b[32m2025-02-23 02:38:06.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.2337 test 0.2007 metric ['0.9031']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 233/233 [00:11<00:00, 19.70it/s]\n",
      "\u001b[32m2025-02-23 02:38:22.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.1912 test 0.1512 metric ['0.9309']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [02:32<00:00, 15.21s/it]\n"
     ]
    }
   ],
   "source": [
    "model = rnn_models.AttentionGRU()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=datastreamer.stream(),\n",
    "    validdataloader=datastreamer.stream(),\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device='cpu',\n",
    "    )\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
