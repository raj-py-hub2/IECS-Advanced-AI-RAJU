{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mltrainer import tokenizer\n",
    "import mltrainer\n",
    "mltrainer.__version__\n",
    "\n",
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the IMDB dataset. This is the MNIST for language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-21 14:24:09.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/imdb\u001b[0m\n",
      "\u001b[32m2025-02-21 14:24:09.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/imdb/aclImdb_v1.tar.gz\u001b[0m\n",
      "\u001b[32m2025-02-21 14:24:12.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.factories.basicfactories\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mCreating TextDatasets from 25000 trainfilesand 25000 testfiles.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 25000/25000 [00:00<00:00, 68924.55it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 25000/25000 [00:00<00:00, 67723.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "imdbdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.IMDB)\n",
    "datasets = imdbdatasetfactory.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets[\"train\"]\n",
    "testdataset = datasets[\"valid\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of 50k movie reviews, labeled positive or negative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's have a look at the first datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Moonchild is a very difficult movie to categorise. It's easiest to think of it as several snapshots of the lives of the two central characters. The fact that these characters are members of a street gang set in an multicultural city of the near future and that one of them is a vampire does not preclude them from having moments like any other people, and this is one of the places where this movie is different to anything else I've ever heard of. It doesn't get wrapped up in the fact that one of the main characters is a vampire, it's just something that has to be dealt with like any other problem. The way the characters interact is surprisingly realistic- there are embarrassing relatives and tricks that are meant to look cool that just don't work, which leaves the film with a lovely sense of not taking itself too seriously for the most part.<br /><br />The other area that really stood out to me is the languages. The fictional city of Mallepa contains various cultural groups, and characters speak the language that they would be expected to speak. Japanese gang members speak Japanese to each other, but Chinese when talking to characters of Chinese descent. Possibly the most amusing exchange involves an Australian and is conducted in English. The actors of the four arguably main characters have three separate mother tongues between them and speak varying levels of each others' languages, so it's quite a feat that the movie was made at all. Which, I suppose, brings me to the lead actors.<br /><br />Much has been made of the fact that the movie stars two of Japan's biggest rockstars, Gackt and Hyde, as well as Taiwanese superstar Lee-hom Wang, whether it is to praise them for their acting or criticise it or simply fangirl about them. In my opinion, Lee-hom is the best at playing a straight and realistic character. However, any lack of acting ability on Gackt's part is mostly masked by the fact that the character he plays is prone to being over-dramatic. I wasn't sure if Hyde's character was supposed to be as sulky and sarcastic as he came across, but it doesn't really detract from the movie either way.<br /><br />There are several scenes which take rather melodramatic turns, which made it difficult for them to affect me much emotionally (Although this doesn't seem to stop a lot of people). I found it's best to just enjoy the movie for what it is and not take it too seriously- It's perfect for getting out and watching with a group of friends. It does have its flaws, but overall it was very enjoyable and I'd highly recommend it to anyone who doesn't mind a few subtitles.\",\n",
       " 'pos')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[0]\n",
    "x, y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is messy data. We have Uppercase, punctuation, and even html tags. Let's clean that out in order to reduce dimensionality, without loosing too much information about the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "punctuation = f\"[{string.punctuation}]\"\n",
    "punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    punctuation = f\"[{string.punctuation}]\"\n",
    "    # remove CaPiTaLs\n",
    "    lowercase = text.lower()\n",
    "    # change don't and isn't into dont and isnt\n",
    "    neg = re.sub(\"\\\\'\", \"\", lowercase)\n",
    "    # swap html tags for spaces\n",
    "    html = re.sub(\"<br />\", \" \", neg)\n",
    "    # swap punctuation for spaces\n",
    "    stripped = re.sub(punctuation, \" \", html)\n",
    "    # remove extra spaces\n",
    "    spaces = re.sub(\"  +\", \" \", stripped)\n",
    "    return spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('moonchild is a very difficult movie to categorise its easiest to think of it as several snapshots of the lives of the two central characters the fact that these characters are members of a street gang set in an multicultural city of the near future and that one of them is a vampire does not preclude them from having moments like any other people and this is one of the places where this movie is different to anything else ive ever heard of it doesnt get wrapped up in the fact that one of the main characters is a vampire its just something that has to be dealt with like any other problem the way the characters interact is surprisingly realistic there are embarrassing relatives and tricks that are meant to look cool that just dont work which leaves the film with a lovely sense of not taking itself too seriously for the most part the other area that really stood out to me is the languages the fictional city of mallepa contains various cultural groups and characters speak the language that they would be expected to speak japanese gang members speak japanese to each other but chinese when talking to characters of chinese descent possibly the most amusing exchange involves an australian and is conducted in english the actors of the four arguably main characters have three separate mother tongues between them and speak varying levels of each others languages so its quite a feat that the movie was made at all which i suppose brings me to the lead actors much has been made of the fact that the movie stars two of japans biggest rockstars gackt and hyde as well as taiwanese superstar lee hom wang whether it is to praise them for their acting or criticise it or simply fangirl about them in my opinion lee hom is the best at playing a straight and realistic character however any lack of acting ability on gackts part is mostly masked by the fact that the character he plays is prone to being over dramatic i wasnt sure if hydes character was supposed to be as sulky and sarcastic as he came across but it doesnt really detract from the movie either way there are several scenes which take rather melodramatic turns which made it difficult for them to affect me much emotionally although this doesnt seem to stop a lot of people i found its best to just enjoy the movie for what it is and not take it too seriously its perfect for getting out and watching with a group of friends it does have its flaws but overall it was very enjoyable and id highly recommend it to anyone who doesnt mind a few subtitles ',\n",
       " 'pos')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(x), y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Now we need to create a vocabulary, which is a mapping from every unique word to an arbitrary integer. We have seen this in lesson 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-21 14:24:14.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.tokenizer\u001b[0m:\u001b[36mbuild_vocab\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mFound 79808 tokens\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import tokenizer\n",
    "\n",
    "v = tokenizer.build_vocab(corpus, max=10000)\n",
    "len(v)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after cleaning, we have about 80k unique tokens. This is even more without the cleaning, because \"The\" and \"the\" will be two different tokens.\n",
    "\n",
    "We also have tokens for unknown words, and for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[\"<UNK>\"], v[\"<PAD>\"], v[\"sdflkjl\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maps a sentence of words to a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1980, 7, 145, 13, 33, 217, 19, 586, 83]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v[word] for word in clean(x).split()[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional, Callable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(\n",
    "        self, max: int, vocab: Vocab, clean: Optional[Callable] = None\n",
    "    ) -> None:\n",
    "        self.max = max\n",
    "        self.vocab = vocab\n",
    "        self.clean = clean\n",
    "\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        if label == \"neg\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def __call__(self, batch: List) -> Tuple[Tensor, Tensor]:\n",
    "        labels, text = [], []\n",
    "        for x, y in batch:\n",
    "            if clean is not None:\n",
    "                x = self.clean(x)\n",
    "            x = x.split()[: self.max]\n",
    "            tokens = torch.tensor([self.vocab[word] for word in x])\n",
    "            text.append(tokens)\n",
    "            labels.append(self.cast_label(y))\n",
    "\n",
    "        text_ = pad_sequence(text, batch_first=True, padding_value=0)\n",
    "        return text_, torch.tensor(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is necessary to:\n",
    "- cut of long sentences to get equal length. 100 words will be enough to get the sentiment in most cases\n",
    "- we need to cast the labels \"neg\" and \"pos\" to integers\n",
    "- we also pad if a sentence is shorter than the max lenght\n",
    "\n",
    "We can feed the preprocessor to the default dataloader from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "preprocessor = Preprocessor(max=100, vocab=v, clean=clean)\n",
    "dataloader = DataLoader(\n",
    "    traindataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get batched sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]), torch.Size([32]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1027,    2,   19, 6274,    7, 4077,  444,   20,    2, 6163,    5, 2571,\n",
       "         174, 7790, 6274, 7569,    1,    1,    2,    1, 1786, 2866, 7940, 2857,\n",
       "         164, 3124,   35, 2177,   53,    4,  602,    5,   14,   73,   14, 6601,\n",
       "        8629,    3,    1,    1,    3, 2391,    1, 1245, 1089,  311,   24,  104,\n",
       "           1,    8,    1,   60,  268,   41,   86, 2491,    3, 1132,    4, 4399,\n",
       "        1245, 6274,   63,    7,  817, 8458,    7,  639,    1,    3, 2491,   14,\n",
       "        6345, 2060,    1,  842,   31,    2,  126,    5,   24,  610,   14,    4,\n",
       "         349,  174, 7790, 6274,   18,   35,  298,    8,    2,   17, 2512,   12,\n",
       "           4,  109,   14,    4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this code is wrapped into the DatasetFactoryProvider, which you can see in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
