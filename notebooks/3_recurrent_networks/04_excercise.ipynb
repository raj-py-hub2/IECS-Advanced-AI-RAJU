{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gin\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatch™, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 18:00:12.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:00<00:00, 5759.56it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:00<00:00, 5869.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30, 3]),\n",
       " tensor([ 6, 16,  9,  1,  2, 13,  6,  2, 11,  8, 14,  3,  6,  0, 10, 18, 10,  8,\n",
       "         17, 18,  4,  6,  0, 17, 12, 10,  2, 18, 14,  4,  0, 16]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 34, 3]),\n",
       " tensor([13, 10,  3,  0, 17,  0,  3, 13, 15,  8,  1,  7,  0,  8,  2, 18, 10, 15,\n",
       "          6, 12, 18, 14, 13,  6,  3,  5,  8,  8, 17,  5,  1, 15]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "- What does it mean that the shapes are sometimes (32, 29, 3), but a second time might look like (32, 31, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? \n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**The shape of `x` in (32, 29, 3) and (32, 31, 3) means there are 32 samples in a batch, each with a sequence of different lengths (29, 31, etc.), and each step has 3 features. Sequences have different lengths because each sample is recorded for different timesteps. Some might have 29 timesteps, others 31. So, each batch adjusts to the longest sequence in it instead of having a fixed length.**\n",
    "\n",
    "</font>\n",
    "\n",
    "- How does the model handle this? \n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**RNNs and LSTMs can handle variable-length sequences, but when processing in batches, they usually need sequences to be the same length within a batch for efficient computation. This is why padding is often used to match the longest sequence in a batch. So, while RNNs/LSTMs don't inherently require a fixed number of timesteps, batch training typically requires padding or packing to handle variable-length inputs efficiently.**\n",
    "</font>\n",
    "\n",
    "\n",
    "- Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**It is already padded with zeros to match the longest sequence within the batch. The `PaddedPreprocessor()` takes care of padding, ensuring all sequences in a batch have the same length for efficient processing. It can also be seen in the following cell-output. The `x` is padded with zeros at the end of the sequence.**\n",
    "</font>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6049, -1.6855,  9.6534],\n",
       "        [-2.6049, -1.3791,  9.3470],\n",
       "        [-2.7581, -1.5323,  9.9599],\n",
       "        [-3.0646, -1.9920, 10.8793],\n",
       "        [-3.6775, -0.7661,  8.2744],\n",
       "        [-3.0646, -0.7661,  0.4597],\n",
       "        [ 0.1532, -1.9920, -4.2904],\n",
       "        [ 9.5002, -5.5162,  2.6049],\n",
       "        [22.0650, -2.1452, 11.3389],\n",
       "        [19.3068, -2.4517, 14.8632],\n",
       "        [11.9519, -2.4517, 12.5648],\n",
       "        [15.1697, -4.4436,  9.6534],\n",
       "        [19.3068, -3.8307,  9.0405],\n",
       "        [15.7826, -2.6049,  3.5243],\n",
       "        [ 5.6695, -0.1532, -0.4597],\n",
       "        [-0.3065,  2.2984,  2.7581],\n",
       "        [-1.3791,  4.7501,  5.3630],\n",
       "        [-1.6855,  6.2824,  7.3550],\n",
       "        [-1.9920,  4.1372,  9.0405],\n",
       "        [-1.8387,  3.8307,  8.7340],\n",
       "        [-1.0726,  3.3710,  9.8067],\n",
       "        [-0.7661,  2.6049,  9.8067],\n",
       "        [-1.6855,  2.7581,  9.1937],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "<font color='green'>\n",
    "\n",
    "**The `gestures.gin` file is modified to include the requred parameters values. `horizon` parameter is changed to match the number of classes in out case (i.e. 20). The other varaibles are initialized like `input_size=3` (number of features), `hidden_size=128`, and `num_layers=3`. It can be modified accordingly to improve the results.**\n",
    "</font>\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-13 23:52:57.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir d:\\Workspace\\upperkaam\\notebooks_review\\Deliverable_Part_1\\notebooks\\3_recurrent_networks\\gestures\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "epochs: 50\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.GIN: 1>, <ReportTypes.TENSORBOARD: 2>, <ReportTypes.MLFLOW: 3>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\conda_kernel\\Lib\\site-packages\\gin\\config.py:615: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n",
      "  decorated_class = decorating_meta(cls.__name__, (cls,), overrides)\n"
     ]
    }
   ],
   "source": [
    "gin.parse_config_file(\"gestures.gin\")\n",
    "model = rnn_models.BaseRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Note:** The above warning is due to library mismatch. This is an depreceation warning and it will not impact in the results of our experiments.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 3, 'hidden_size': 128, 'num_layers': 3, 'horizon': 20}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"BaseRNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**The above cell-output shows the parameters for our model that we defined in the `genture.gin` file.**.\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** The output from the model represent a softmax layer output, which provide the probability for each class to be the correct answer. So, that is why we have 20 values for each sample as we have 20 classes. We have to perform further opeations to get 1 actual class value for each sample we provide.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0312)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** The results from blind guessing will always be not appropiate as we haven't trained the model with our dataset. So, testing the model before any training performed will always produce poor results. Here, the accuracy is 0.03% in the blind guessing scenario.\n",
    "</font>\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 20]), torch.Size([32]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0747, -0.0717, -0.0035, -0.0010, -0.1243, -0.0194, -0.0434, -0.0391,\n",
       "         -0.0643, -0.0120, -0.0018, -0.0682,  0.0706,  0.0907, -0.0356, -0.1305,\n",
       "         -0.0114, -0.1306, -0.0176,  0.0217], grad_fn=<SelectBackward0>),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0], y[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** The model's output comes from a softmax layer, which gives the probability of each class being the correct answer. To get the final class prediction, we need to apply `argmax` to select the class with the highest probability.\n",
    "</font>\n",
    "\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9904, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 3, 'hidden_size': 128, 'num_layers': 3, 'horizon': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"BaseRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# however, it might speed up training for larger models, with more parameters\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/13 23:55:09 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/02/13 23:55:09 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/02/13 23:55:10 INFO mlflow.tracking.fluent: Experiment with name 'gestures' does not exist. Creating a new experiment.\n",
      "2025/02/13 23:55:11 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "\u001b[32m2025-02-13 23:55:11.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures\\20250213-235511\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.15it/s]\n",
      "\u001b[32m2025-02-13 23:55:26.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.6575 test 2.5737 metric ['0.1000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.92it/s]\n",
      "\u001b[32m2025-02-13 23:55:35.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.4530 test 2.4951 metric ['0.0969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.47it/s]\n",
      "\u001b[32m2025-02-13 23:55:46.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 2.5356 test 2.4600 metric ['0.1219']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.33it/s]\n",
      "\u001b[32m2025-02-13 23:55:56.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 2.4504 test 2.3490 metric ['0.1344']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00,  9.42it/s]\n",
      "\u001b[32m2025-02-13 23:56:06.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 2.4859 test 2.4470 metric ['0.1062']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00,  9.23it/s]\n",
      "\u001b[32m2025-02-13 23:56:15.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 2.4258 test 2.4608 metric ['0.1234']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.53it/s]\n",
      "\u001b[32m2025-02-13 23:56:27.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 2.5608 test 2.6298 metric ['0.0859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.20it/s]\n",
      "\u001b[32m2025-02-13 23:56:39.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 2.6524 test 2.5077 metric ['0.1016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  8.02it/s]\n",
      "\u001b[32m2025-02-13 23:56:50.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 2.6030 test 2.7149 metric ['0.0891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.23it/s]\n",
      "\u001b[32m2025-02-13 23:57:02.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 2.5095 test 2.4268 metric ['0.1156']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.30it/s]\n",
      "\u001b[32m2025-02-13 23:57:14.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 2.3976 test 2.3623 metric ['0.1313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.14it/s]\n",
      "\u001b[32m2025-02-13 23:57:27.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 2.4715 test 2.4999 metric ['0.1297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  6.79it/s]\n",
      "\u001b[32m2025-02-13 23:57:39.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 2.3381 test 2.2939 metric ['0.1297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  6.88it/s]\n",
      "\u001b[32m2025-02-13 23:57:52.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 2.3260 test 2.2845 metric ['0.1422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.12it/s]\n",
      "\u001b[32m2025-02-13 23:58:04.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 2.2927 test 2.2804 metric ['0.1359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:16<00:00,  4.85it/s]\n",
      "\u001b[32m2025-02-13 23:58:23.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 2.2595 test 2.2905 metric ['0.1391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:13<00:00,  5.86it/s]\n",
      "\u001b[32m2025-02-13 23:58:37.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 2.2545 test 2.3823 metric ['0.1359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.42it/s]\n",
      "\u001b[32m2025-02-13 23:58:49.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 2.3968 test 2.3095 metric ['0.1281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.10it/s]\n",
      "\u001b[32m2025-02-13 23:59:01.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 2.2674 test 2.2494 metric ['0.1531']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.44it/s]\n",
      "\u001b[32m2025-02-13 23:59:13.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 2.2373 test 2.2531 metric ['0.1562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  6.79it/s]\n",
      "\u001b[32m2025-02-13 23:59:26.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 2.2539 test 2.1969 metric ['0.1719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.07it/s]\n",
      "\u001b[32m2025-02-13 23:59:39.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 2.1725 test 2.2367 metric ['0.1344']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.28it/s]\n",
      "\u001b[32m2025-02-13 23:59:49.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 2.2604 test 2.5678 metric ['0.1203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.57it/s]\n",
      "\u001b[32m2025-02-14 00:00:00.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 2.3067 test 2.2993 metric ['0.1359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.48it/s]\n",
      "\u001b[32m2025-02-14 00:00:11.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 2.2309 test 2.2067 metric ['0.1750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.82it/s]\n",
      "\u001b[32m2025-02-14 00:00:23.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 2.1945 test 2.1940 metric ['0.1328']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  6.91it/s]\n",
      "\u001b[32m2025-02-14 00:00:35.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 2.1658 test 2.1666 metric ['0.1875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.64it/s]\n",
      "\u001b[32m2025-02-14 00:00:47.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 2.1599 test 2.1508 metric ['0.1828']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:15<00:00,  5.35it/s]\n",
      "\u001b[32m2025-02-14 00:01:03.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 2.1581 test 2.2562 metric ['0.1531']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:12<00:00,  6.61it/s]\n",
      "\u001b[32m2025-02-14 00:01:16.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 2.1899 test 2.1419 metric ['0.1750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.27it/s]\n",
      "\u001b[32m2025-02-14 00:01:26.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 2.1546 test 2.1407 metric ['0.1734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.73it/s]\n",
      "\u001b[32m2025-02-14 00:01:38.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 2.1380 test 2.1362 metric ['0.1891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.22it/s]\n",
      "\u001b[32m2025-02-14 00:01:48.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 32 train 2.1973 test 2.2355 metric ['0.1594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.39it/s]\n",
      "\u001b[32m2025-02-14 00:02:00.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 33 train 2.1841 test 2.3584 metric ['0.1500']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.84it/s]\n",
      "\u001b[32m2025-02-14 00:02:12.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 34 train 2.2812 test 2.1809 metric ['0.1891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:11<00:00,  7.20it/s]\n",
      "\u001b[32m2025-02-14 00:02:24.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 35 train 2.2262 test 2.1257 metric ['0.2094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.79it/s]\n",
      "\u001b[32m2025-02-14 00:02:36.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 36 train 2.1303 test 2.1357 metric ['0.2094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.43it/s]\n",
      "\u001b[32m2025-02-14 00:02:48.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 37 train 2.1254 test 2.1536 metric ['0.1812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.45it/s]\n",
      "\u001b[32m2025-02-14 00:02:59.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 38 train 2.1047 test 2.0631 metric ['0.2234']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.13it/s]\n",
      "\u001b[32m2025-02-14 00:03:10.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 39 train 2.0880 test 2.0446 metric ['0.2422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.72it/s]\n",
      "\u001b[32m2025-02-14 00:03:20.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 40 train 2.0804 test 2.0573 metric ['0.2141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.73it/s]\n",
      "\u001b[32m2025-02-14 00:03:32.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 41 train 2.0425 test 2.0303 metric ['0.2047']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.86it/s]\n",
      "\u001b[32m2025-02-14 00:03:43.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 42 train 2.0465 test 2.3440 metric ['0.1906']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00,  9.09it/s]\n",
      "\u001b[32m2025-02-14 00:03:53.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 43 train 2.2701 test 2.2083 metric ['0.1891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.82it/s]\n",
      "\u001b[32m2025-02-14 00:04:04.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 44 train 2.1293 test 2.0476 metric ['0.2156']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.36it/s]\n",
      "\u001b[32m2025-02-14 00:04:15.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 45 train 2.0966 test 2.0659 metric ['0.2313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.75it/s]\n",
      "\u001b[32m2025-02-14 00:04:26.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 46 train 2.0443 test 2.0284 metric ['0.2281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  8.04it/s]\n",
      "\u001b[32m2025-02-14 00:04:37.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 47 train 2.1195 test 2.2304 metric ['0.1812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.83it/s]\n",
      "\u001b[32m2025-02-14 00:04:48.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 48 train 2.1506 test 2.0343 metric ['0.2281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  7.80it/s]\n",
      "\u001b[32m2025-02-14 00:04:59.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 49 train 2.0602 test 1.9926 metric ['0.2625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [09:46<00:00, 11.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"../../models/gestures/\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "gin.parse_config_file(\"gestures.gin\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"GRUmodel\")\n",
    "    mlflow.set_tag(\"dev\", \"raoul\")\n",
    "    mlflow.log_params(gin.get_bindings(\"BaseRNN\"))\n",
    "\n",
    "    model = rnn_models.BaseRNN()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    modelpath = modeldir / (tag + \"model.pt\")\n",
    "    torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "accuracy(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to update the code above with the following two commands.\n",
    "    \n",
    "```python\n",
    "gin.parse_config_file('gestures_gru.gin')\n",
    "model = rnn_model.GRUmodel()\n",
    "```\n",
    "<font color='green'>\n",
    "\n",
    "The above code is added in the following code section to convert the `BaseRNN` with the `GRUmodel`. The config file `gestures_gru.bin` contains the parameters defination of the GRU model.\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "To discern between the changes, also modify the tag mlflow.set_tag(\"model\", \"new-tag-here\") where you add\n",
    "a new tag of your choice. This way you can keep the models apart.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "A new tag (i.e: `GRUmodel_improve`) is added to seperatelly log the experiments for the GRU model. It will seperate the model logs for later inspection. This is also added in the following code section. Comments are also added to see the changes.\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercises:\n",
    "\n",
    "- improve the RNN model\n",
    "<font color='green'>\n",
    "\n",
    "**Improvements**\n",
    "- RNN model, tends to lack in capturing the long-term relations in the time-series data, whereas LSTM or GRU layers can learn the temporal dependencies in the time-series data. \n",
    "- Hence, we can convert the `BaseRNN` with the `GRUmodel` to get the GRU model. The config file `gestures_gru.bin` contains the defination of the GRU model.\n",
    "\n",
    "</font>\n",
    "\n",
    "- test different things. What works? What does not?\n",
    "<font color='green'>\n",
    "\n",
    "**Answer**\n",
    "- Converting from the `BaseRNN` to `GRUmodel` really improves the model accuracy.\n",
    "- With our previous experience of improviing the model accuracy, I have tested with different values of hidden and layers size. I found that keeping the model simple improves the model and keeps the training time in limit. So, found the combination as `hidden_size=32` and `num_layers=3` (changes are made in the `gestures_gru.bin` file) to acheive best accuracy.\n",
    "\n",
    "</font>\n",
    "\n",
    "- experiment with either GRU or LSTM layers, create your own models + ginfiles. \n",
    "<font color='green'>\n",
    "\n",
    "- **Answer:** The `gestures_gru.bin` file is created to work with the GRU model. We can modify this file to change the model configuration.\n",
    "\n",
    "</font>\n",
    "\n",
    "You should be able to get above 90% accuracy with the dataset.\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** We are able to acheive the accuracy greater than 90% with `hidden_size=32` and `num_layers=3`.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-14 00:12:36.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures\\20250214-001236\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.34it/s]\n",
      "\u001b[32m2025-02-14 00:12:42.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.8885 test 2.5970 metric ['0.1031']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.04it/s]\n",
      "\u001b[32m2025-02-14 00:12:47.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.4697 test 2.3909 metric ['0.1266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.82it/s]\n",
      "\u001b[32m2025-02-14 00:12:53.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 2.3351 test 2.2435 metric ['0.1531']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.68it/s]\n",
      "\u001b[32m2025-02-14 00:12:59.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 2.2035 test 2.1282 metric ['0.2437']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.31it/s]\n",
      "\u001b[32m2025-02-14 00:13:05.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 2.0402 test 1.8908 metric ['0.2938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.40it/s]\n",
      "\u001b[32m2025-02-14 00:13:10.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 1.8204 test 1.6399 metric ['0.4016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 16.07it/s]\n",
      "\u001b[32m2025-02-14 00:13:16.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 1.6120 test 1.4850 metric ['0.3922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.99it/s]\n",
      "\u001b[32m2025-02-14 00:13:21.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 1.4013 test 1.2878 metric ['0.4375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.28it/s]\n",
      "\u001b[32m2025-02-14 00:13:26.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 1.2456 test 1.1555 metric ['0.5156']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.84it/s]\n",
      "\u001b[32m2025-02-14 00:13:32.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 1.1416 test 1.0309 metric ['0.5391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.68it/s]\n",
      "\u001b[32m2025-02-14 00:13:38.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 1.0534 test 0.9496 metric ['0.5625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.96it/s]\n",
      "\u001b[32m2025-02-14 00:13:44.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 0.9813 test 0.9269 metric ['0.5781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.34it/s]\n",
      "\u001b[32m2025-02-14 00:13:49.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 0.9452 test 0.8758 metric ['0.6188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.82it/s]\n",
      "\u001b[32m2025-02-14 00:13:54.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 0.8676 test 0.7806 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.30it/s]\n",
      "\u001b[32m2025-02-14 00:13:59.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 0.8108 test 0.7920 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.70it/s]\n",
      "\u001b[32m2025-02-14 00:14:05.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 0.7492 test 0.7206 metric ['0.6906']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.25it/s]\n",
      "\u001b[32m2025-02-14 00:14:10.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 0.7253 test 0.6809 metric ['0.7188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.23it/s]\n",
      "\u001b[32m2025-02-14 00:14:15.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 0.6727 test 0.6223 metric ['0.7609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 16.11it/s]\n",
      "\u001b[32m2025-02-14 00:14:20.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 0.6030 test 0.5719 metric ['0.8219']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 16.04it/s]\n",
      "\u001b[32m2025-02-14 00:14:26.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 0.5604 test 0.5471 metric ['0.8016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.31it/s]\n",
      "\u001b[32m2025-02-14 00:14:31.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 0.5054 test 0.4918 metric ['0.8484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 12.90it/s]\n",
      "\u001b[32m2025-02-14 00:14:38.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 0.4595 test 0.4374 metric ['0.8688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.19it/s]\n",
      "\u001b[32m2025-02-14 00:14:44.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 0.4405 test 0.4083 metric ['0.8891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.58it/s]\n",
      "\u001b[32m2025-02-14 00:14:49.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 0.4035 test 0.3697 metric ['0.8812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.60it/s]\n",
      "\u001b[32m2025-02-14 00:14:55.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 0.3556 test 0.3148 metric ['0.9203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.17it/s]\n",
      "\u001b[32m2025-02-14 00:15:00.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 0.3140 test 0.2924 metric ['0.9234']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.11it/s]\n",
      "\u001b[32m2025-02-14 00:15:05.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 0.2828 test 0.2953 metric ['0.9172']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.66it/s]\n",
      "\u001b[32m2025-02-14 00:15:10.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 0.2514 test 0.2593 metric ['0.9313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.61it/s]\n",
      "\u001b[32m2025-02-14 00:15:17.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 0.2325 test 0.1860 metric ['0.9609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 16.17it/s]\n",
      "\u001b[32m2025-02-14 00:15:22.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 0.2056 test 0.1778 metric ['0.9656']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.67it/s]\n",
      "\u001b[32m2025-02-14 00:15:27.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 0.1778 test 0.1642 metric ['0.9703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.98it/s]\n",
      "\u001b[32m2025-02-14 00:15:33.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 0.1789 test 0.1578 metric ['0.9641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.85it/s]\n",
      "\u001b[32m2025-02-14 00:15:38.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 32 train 0.1583 test 0.1476 metric ['0.9672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.29it/s]\n",
      "\u001b[32m2025-02-14 00:15:44.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 33 train 0.1429 test 0.1765 metric ['0.9516']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.77it/s]\n",
      "\u001b[32m2025-02-14 00:15:49.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 34 train 0.1559 test 0.1399 metric ['0.9641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.88it/s]\n",
      "\u001b[32m2025-02-14 00:15:55.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 35 train 0.1276 test 0.1423 metric ['0.9672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.65it/s]\n",
      "\u001b[32m2025-02-14 00:16:01.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 36 train 0.1264 test 0.1175 metric ['0.9766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.73it/s]\n",
      "\u001b[32m2025-02-14 00:16:07.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 37 train 0.1214 test 0.1279 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.20it/s]\n",
      "\u001b[32m2025-02-14 00:16:13.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 38 train 0.1318 test 0.1161 metric ['0.9734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.70it/s]\n",
      "\u001b[32m2025-02-14 00:16:19.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 39 train 0.1003 test 0.1085 metric ['0.9797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 15.29it/s]\n",
      "\u001b[32m2025-02-14 00:16:25.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 40 train 0.0836 test 0.1294 metric ['0.9672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.97it/s]\n",
      "\u001b[32m2025-02-14 00:16:31.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 41 train 0.0811 test 0.0995 metric ['0.9797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.70it/s]\n",
      "\u001b[32m2025-02-14 00:16:37.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 42 train 0.0919 test 0.1144 metric ['0.9781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 13.09it/s]\n",
      "\u001b[32m2025-02-14 00:16:43.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 43 train 0.0949 test 0.0984 metric ['0.9812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.90it/s]\n",
      "\u001b[32m2025-02-14 00:16:50.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 44 train 0.0849 test 0.1259 metric ['0.9672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.19it/s]\n",
      "\u001b[32m2025-02-14 00:16:56.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 45 train 0.0856 test 0.1201 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.23it/s]\n",
      "\u001b[32m2025-02-14 00:17:02.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 46 train 0.0719 test 0.1105 metric ['0.9766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.82it/s]\n",
      "\u001b[32m2025-02-14 00:17:08.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 47 train 0.0606 test 0.1227 metric ['0.9734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 14.52it/s]\n",
      "\u001b[32m2025-02-14 00:17:14.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 48 train 0.0709 test 0.1199 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:05<00:00, 13.74it/s]\n",
      "\u001b[32m2025-02-14 00:17:20.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 49 train 0.1124 test 0.1395 metric ['0.9688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [04:44<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# use the new GRU model by using the 'gestures_gru.gin' file\n",
    "# the parameters are defined in that file for the GRU model\n",
    "# CODE CHANGES ARE HERE!!\n",
    "gin.parse_config_file('gestures_gru.gin')\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    optimizer_kwargs={'lr': 0.001, 'weight_decay': 1e-05},\n",
    "    earlystop_kwargs=None\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # The tag is added to diffirentiate the GRU model improvement experiments.\n",
    "    # CODE CHANGES ARE HERE!!\n",
    "    mlflow.set_tag(\"model\", \"GRUmodel_improve\")\n",
    "    \n",
    "    mlflow.set_tag(\"dev\", \"raoul\")\n",
    "    mlflow.log_params(gin.get_bindings(\"GRUmodel\"))\n",
    "\n",
    "    # The following code will load the GRU model\n",
    "    # the parameters for the GRU model is defined in the 'gestures_gru.gin' file\n",
    "    # CODE CHANGES ARE HERE!!\n",
    "    model = rnn_models.GRUmodel()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    modelpath = modeldir / (tag + \"model.pt\")\n",
    "    torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9688)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "accuracy(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "The accruacy of the model validates that we now have better accuracy over the `BaseRNN` by using the `GRUmodel`, which is more efficient in capturing the time-series data and tends to achieve better results as compared to the vaniala RNNs. We are able to acheive the accuracy of 96% with `hidden_size=32` and `num_layers=3`. This is the best config for the model, with the experiments I performed.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
