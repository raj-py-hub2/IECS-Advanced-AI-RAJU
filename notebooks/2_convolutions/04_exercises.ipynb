{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "## Import libraries\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import gin\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Let's use the same dataset from the previous session i.e. Fashion MNIST**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:10:49.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 16:10:49.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "batchsize = 64\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adding dropout and normalization layers\n",
    "Study the pytorch documentation for:\n",
    "- Dropout https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "- normalization layers https://pytorch.org/docs/stable/nn.html#normalization-layers\n",
    "\n",
    "Experiment with adding dropout and normalization layers to your model. Some rough guidelines where to add them relative to Linear or Conv2d layers:\n",
    "- Dropout: after Linear or Conv2d layers. Often added after the last Linear layer *before* the output layer, but could occur more often.\n",
    "- Normalization layers: right after (blocks of) Linear or Conv2d layers, but before activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "Dropout and Normalization layers are added to avoid wieghts overflow and able the model to learn better generalized weights.\n",
    "\n",
    "- Adding BatchNorm layer after each Conv2D and Linear layer to normalize the weigths.\n",
    "\n",
    "- Adding Dropout after each Linear layer to reduce the overfitting effect. The dropout rate (e.g., 0.5) represents the probability of dropping a neuron, with higher values increasing regularization but potentially slowing learning.\n",
    "\n",
    "- We will be using `gin-config` to configure our custom CNN model, hence, we need to make it configurable. Please read the folloiwng note to understand what is happening in the code.\n",
    "\n",
    "**Important note: to make `gin configurable` function, we have include two lines of code before the function defination.**\n",
    "1. **gin.enter_interactive_mode()**\n",
    "1. **@gin.configurable**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:10:49.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mAggregating activation map with size torch.Size([2, 2])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "              ReLU-3           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 32, 14, 14]               0\n",
      "            Conv2d-5           [-1, 64, 12, 12]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 12, 12]             128\n",
      "              ReLU-7           [-1, 64, 12, 12]               0\n",
      "         MaxPool2d-8             [-1, 64, 6, 6]               0\n",
      "            Conv2d-9             [-1, 64, 4, 4]          36,928\n",
      "      BatchNorm2d-10             [-1, 64, 4, 4]             128\n",
      "             ReLU-11             [-1, 64, 4, 4]               0\n",
      "        MaxPool2d-12             [-1, 64, 2, 2]               0\n",
      "        AvgPool2d-13             [-1, 64, 1, 1]               0\n",
      "          Flatten-14                   [-1, 64]               0\n",
      "           Linear-15                  [-1, 128]           8,320\n",
      "      BatchNorm1d-16                  [-1, 128]             256\n",
      "             ReLU-17                  [-1, 128]               0\n",
      "          Dropout-18                  [-1, 128]               0\n",
      "           Linear-19                   [-1, 64]           8,256\n",
      "      BatchNorm1d-20                   [-1, 64]             128\n",
      "             ReLU-21                   [-1, 64]               0\n",
      "          Dropout-22                   [-1, 64]               0\n",
      "           Linear-23                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 73,674\n",
      "Trainable params: 73,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.88\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 1.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "\n",
    "# CNN model with BatchNorm and Dropout\n",
    "\"\"\"\n",
    "The following two lines of code is added to make our custom CNN model configurable with gin-config\n",
    "These two lines are very important other you model will give error.\n",
    "\"\"\"\n",
    "gin.enter_interactive_mode()\n",
    "@gin.configurable\n",
    "class CNN_custom(nn.Module):\n",
    "    def __init__(self, filters, units1, units2, input_size=(32, 1, 28, 28), dropout_rate=0.5) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.filters = filters\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(filters),            # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(filters, filters * 2, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(filters * 2),        # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(filters * 2, filters * 2, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(filters * 2),       # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        activation_map_size = self._conv_test(input_size)\n",
    "        logger.info(f\"Aggregating activation map with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters * 2, units1),\n",
    "            nn.BatchNorm1d(units1),             # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),           # Added Dropout here\n",
    "\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.BatchNorm1d(units2),             # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),          # Added Dropout here\n",
    "\n",
    "            nn.Linear(units2, 10)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size=(32, 1, 28, 28)):\n",
    "        x = torch.ones(input_size)\n",
    "        x = self.convolutions(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "model = CNN_custom(filters=32, units1=128, units2=64).to('cpu')\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding convolutional and pooling layers\n",
    "Previous lessons, you have started to experiment with you model.\n",
    "You might have tested the impact of the amount of units, the depth of layers and different learning rates.\n",
    "\n",
    "This lesson, we have added some new types of layers: convolutional and pooling layers.\n",
    "Experiment with adding these new layers.\n",
    "<font color='green'>\n",
    "\n",
    "**A pooling layer is added to reduces the size of feature maps by taking the most important information, usually by selecting the maximum value (max pooling) or the average value (average pooling) in a small window. We use it to make the model faster, reduce memory usage, and make the model more stable by keeping only the key features. It helps the model by reducing overfitting and making it better at recognizing patterns even if they change a little. If we don’t use pooling, the model will be too large, slower, and more sensitive to small changes in the input, which can make it less accurate. `nn.MaxPool2d(kernel_size=2)` will add a max pooling layer to the model to extract maximum value from the 2x2 grid in the feature map.**\n",
    "\n",
    "</font>\n",
    "\n",
    "Also, have a look at the `ModuleList`: https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#modulelist\n",
    "It can be really useful to create a list of layers from a configfile, and then use that list to create your model.\n",
    "Instead of just adding a single layer, you could also add a block of layers (eg a Conv2d layer, followed by a ReLU layer, followed by a BatchNorm2d layer, followed by a MaxPool2d layer) and repeat that in a loop, adding it to the `ModuleList`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**For easy readability of the code, we can include `ModuleList` to combine the blocks of layers into one, just like a list. This helps in organizing multiple layers or blocks in a structured way, making the model definition cleaner and easier to manage.**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with nn.Module\n",
    "class CNN_ModuleList(nn.Module):\n",
    "    def __init__(self, conv_layers_config, units1, units2, input_size=(32, 1, 28, 28), dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        conv_layers_config: List defining number of conv layers and filters per layer.\n",
    "        Example: [(filters, kernel_size, stride, padding), (filters*2, kernel_size, stride, padding)]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Creating convolutional layers dynamically using ModuleList\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        in_channels = 1  # Initial input (grayscale image)\n",
    "\n",
    "        \"\"\"\n",
    "        without explicitly adding each layer CNN-block one by one,\n",
    "        we can do this with 'ModuleList', which is iteratable in the training regime... \n",
    "        \"\"\"\n",
    "        for filters, kernel_size, stride, padding in conv_layers_config:\n",
    "            self.convolutions.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, filters, kernel_size=kernel_size, stride=stride, padding=padding),  # Added Conv2d here\n",
    "                nn.BatchNorm2d(filters),        # Added BatchNorm here\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)  # added Max-pooling layer\n",
    "            ))\n",
    "            in_channels = filters  # Update channels for next layer\n",
    "\n",
    "        # Compute final activation map size\n",
    "        activation_map_size = self._conv_test(input_size)\n",
    "        logger.info(f\"Aggregating activation map with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, units1),\n",
    "            nn.BatchNorm1d(units1),             # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),           # Added dropout here\n",
    "\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.BatchNorm1d(units2),             # Added BatchNorm here\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),           # Added dropout here\n",
    "\n",
    "            nn.Linear(units2, 10)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size=(32, 1, 28, 28)):\n",
    "        x = torch.ones(input_size)\n",
    "        for layer in self.convolutions:\n",
    "            x = layer(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    # this is the forward function that uses called when data to passed to the model....\n",
    "    def forward(self, x):\n",
    "        for layer in self.convolutions:\n",
    "            x = layer(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**To initialize this CNN model we first need to configure the list to include each block paramerters.**\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:10:49.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mAggregating activation map with size torch.Size([2, 2])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "              ReLU-3           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 32, 14, 14]               0\n",
      "            Conv2d-5           [-1, 64, 12, 12]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 12, 12]             128\n",
      "              ReLU-7           [-1, 64, 12, 12]               0\n",
      "         MaxPool2d-8             [-1, 64, 6, 6]               0\n",
      "            Conv2d-9             [-1, 64, 4, 4]          36,928\n",
      "      BatchNorm2d-10             [-1, 64, 4, 4]             128\n",
      "             ReLU-11             [-1, 64, 4, 4]               0\n",
      "        MaxPool2d-12             [-1, 64, 2, 2]               0\n",
      "        AvgPool2d-13             [-1, 64, 1, 1]               0\n",
      "          Flatten-14                   [-1, 64]               0\n",
      "           Linear-15                  [-1, 128]           8,320\n",
      "      BatchNorm1d-16                  [-1, 128]             256\n",
      "             ReLU-17                  [-1, 128]               0\n",
      "          Dropout-18                  [-1, 128]               0\n",
      "           Linear-19                   [-1, 64]           8,256\n",
      "      BatchNorm1d-20                   [-1, 64]             128\n",
      "             ReLU-21                   [-1, 64]               0\n",
      "          Dropout-22                   [-1, 64]               0\n",
      "           Linear-23                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 73,674\n",
      "Trainable params: 73,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.88\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 1.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example: [(filters, kernel_size, stride, padding)]\n",
    "conv_layers_config = [(32, 3, 1, 1),        # For 1st CNN-block\n",
    "                      (32*2, 3, 1, 0),      # For 2nd CNN-block\n",
    "                      (32*2, 3, 1, 0)]      # For 3rd CNN-block\n",
    "\n",
    "model = CNN_ModuleList(conv_layers_config=conv_layers_config, units1=128, units2=64).to('cpu')\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Improve your pipeline\n",
    "In addition to new layers, we have expanded our logging tools with MLFlow, so we currently can choose between gin-config, tensorboard and MLFlow.\n",
    "\n",
    "Expand your training pipeline you started in the previous lesson such that:\n",
    "\n",
    "- you can switch between models by changing a config file\n",
    "<font color='green'>\n",
    "\n",
    "**Answer: Instead of hardcoding architectures & hyperparameters, store them in a config file. You can check the paramters in the `model.gin` file.**\n",
    "\n",
    "</font>\n",
    "- you can test different hyperparameters by changing a config file\n",
    "<font color='green'>\n",
    "\n",
    "**Answer: The `model.gin` file contains the paremeters for our `CNN_custom` model. The file is easily configurable to change the parameters of the model. After modifying the `model.gin` you have to load the file again in the notebook, so the changed parameters are loaded successfully.**\n",
    "\n",
    "</font>\n",
    "- you automatically log settings: model picked, hyperparameters, metrics, etc. : use either gin-config, tensorboard or MLFlow to log that, or a combination, whatever you prefer.\n",
    "<font color='green'>\n",
    "\n",
    "**Answer: All the experiments will be logged in the `modellogs` directory with the timestamps. Each experiment directory will contains 2 files; `saved_config.gin` (contains experiemnt configuration) and `events` file (contains tensorboard logs during tarining for loss and accuracy values.)**\n",
    "\n",
    "</font>\n",
    "- Important: doing a master means you don't just start engineering a pipeline, but you need to reflect. Why do you see the results you see? What does this mean, considering the theory? Write down lessons learned and reflections, based on experimental results.\n",
    "<font color='green'>\n",
    "\n",
    "**Answer: In this excercise, we are advised to use a CNN model to train the `FashionMNIST` dataset. The main aim for this excercise is to develop a training pipeline. Firstly, we develop a custom CNN architecture class `CNN_custom` by adding `BatchNorm` and `dropout` layers to regularization to the model for better generalization of the dataset. This `CNN_custom` is configurable with `gin-config`, so we added a config file called `model.gin` with all the parameters required for our CNN architecture. The file is easily configurable to change the parameters of the model.**\n",
    "\n",
    "**Now, lets ponder on the results we obtained from this excercise. Adding regulariation is always better for better generalization of the model as it avoids the model to overfit. The `BatchNorm` layer tries to normalize the trained weights to avoid exploding gradient issue which can cause deviation from the local minima. This exploding gradient also can cause the model to deviates from the learning, hence the loss is increased. The `dropout` layer adds a regularization effect to the model to restrict the model to overfitting on the training example.**\n",
    "\n",
    "**From the results, we can observed that the added layers helps the model to learn faster as compared to the model in `02_convolutions` notebook file. However, the final accuracy is almost similar but the learning curve is improved for our new model. It may means that we have maxed the accuracy for the provided dataset and adding more layers might not have huge impact on the final accuracy.**\n",
    "\n",
    "</font>\n",
    "\n",
    "- continuously improve your code: \n",
    "    - clean up your experimental environment, such that it doesnt get too messy\n",
    "    - automate the boring stuff: use a Makefile, use configfiles, automate logging, etc.\n",
    "    - use git: commit your changes often and with descriptive messages\n",
    "    - separate code for pipelines, configs, models, modeltraining and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Instead of hardcoding architectures & hyperparameters, store them in a config file `model.gin`. You can check the parameters in the `model.gin` file.**\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='model.gin', imports=['gin.torch.external_configurables'], includes=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import gin\n",
    "\n",
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Now we can use the defined parameters of the model to initialize the model accordingly. Hence, by changing only the config file we can change the parameters of the model. It is more conviniennt then working with hardcoded parameters.**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:10:49.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mAggregating activation map with size torch.Size([2, 2])\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CNN model wrt the config file defined in model.gin\n",
    "model = CNN_custom().to('cpu')\n",
    "\n",
    "# we will use `Adam` optimizer for the following task....\n",
    "optimizer = optim.Adam\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs/\",\n",
    "    train_steps=len(streamers[\"train\"]),\n",
    "    valid_steps=len(streamers[\"valid\"]),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:10:49.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-161049\u001b[0m\n",
      "\u001b[32m2025-02-17 16:10:49.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:45<00:00, 20.47it/s]\n",
      "\u001b[32m2025-02-17 16:11:38.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5744 test 0.3426 metric ['0.8775']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:44<00:00, 20.92it/s]\n",
      "\u001b[32m2025-02-17 16:12:26.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3407 test 0.2924 metric ['0.8971']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:46<00:00, 20.28it/s]\n",
      "\u001b[32m2025-02-17 16:13:15.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.2887 test 0.2912 metric ['0.8883']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:45<00:00, 20.69it/s]\n",
      "\u001b[32m2025-02-17 16:14:03.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.2559 test 0.2512 metric ['0.9096']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:44<00:00, 21.03it/s]\n",
      "\u001b[32m2025-02-17 16:14:51.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2327 test 0.2353 metric ['0.9130']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:45<00:00, 20.63it/s]\n",
      "\u001b[32m2025-02-17 16:15:39.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 0.2136 test 0.2449 metric ['0.9156']\u001b[0m\n",
      "\u001b[32m2025-02-17 16:15:39.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2353, current loss 0.2449.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:40<00:00, 22.96it/s]\n",
      "\u001b[32m2025-02-17 16:16:23.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 0.1974 test 0.2346 metric ['0.9202']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:41<00:00, 22.39it/s]\n",
      "\u001b[32m2025-02-17 16:17:07.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 0.1828 test 0.2340 metric ['0.9199']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:40<00:00, 22.86it/s]\n",
      "\u001b[32m2025-02-17 16:17:51.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.1681 test 0.2474 metric ['0.9155']\u001b[0m\n",
      "\u001b[32m2025-02-17 16:17:51.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2340, current loss 0.2474.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:42<00:00, 22.27it/s]\n",
      "\u001b[32m2025-02-17 16:18:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.1568 test 0.2621 metric ['0.9119']\u001b[0m\n",
      "\u001b[32m2025-02-17 16:18:35.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2340, current loss 0.2621.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [07:45<00:00, 46.60s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device='cpu',\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "we can observe that the added layers helps the model to learn faster as compared to the model in `02_convolutions` notebook file. However, the final accuracy is almost similar but the learning curve is improved for our new model. It may means that we have maxed the accuracy for the provided dataset and adding more layers might not have huge impact on the final accuracy.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "#### Extra experiment ...\n",
    "\n",
    "**As we see in our previous experiment that accuracy is around 91%, so can we increase the accuracy by increasing the number of layers and filter size? to find out this lets perform another experiment.**\n",
    "\n",
    "**Lets again utilize the `CNN_ModuleList` class to initialize the CNN architecture that we previously defined. The configuration of the model is defined below. We have in total 4 CNN-blocks and then 2 Linear layers acting as the classification layer.**\n",
    "\n",
    "**Note: this model will take some time to train. On my PC, it took around 20mins to train.**\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:53:38.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mAggregating activation map with size torch.Size([1, 1])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             640\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "              ReLU-3           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 64, 14, 14]               0\n",
      "            Conv2d-5          [-1, 256, 14, 14]         147,712\n",
      "       BatchNorm2d-6          [-1, 256, 14, 14]             512\n",
      "              ReLU-7          [-1, 256, 14, 14]               0\n",
      "         MaxPool2d-8            [-1, 256, 7, 7]               0\n",
      "            Conv2d-9            [-1, 256, 7, 7]         590,080\n",
      "      BatchNorm2d-10            [-1, 256, 7, 7]             512\n",
      "             ReLU-11            [-1, 256, 7, 7]               0\n",
      "        MaxPool2d-12            [-1, 256, 3, 3]               0\n",
      "           Conv2d-13            [-1, 128, 3, 3]         295,040\n",
      "      BatchNorm2d-14            [-1, 128, 3, 3]             256\n",
      "             ReLU-15            [-1, 128, 3, 3]               0\n",
      "        MaxPool2d-16            [-1, 128, 1, 1]               0\n",
      "        AvgPool2d-17            [-1, 128, 1, 1]               0\n",
      "          Flatten-18                  [-1, 128]               0\n",
      "           Linear-19                  [-1, 512]          66,048\n",
      "      BatchNorm1d-20                  [-1, 512]           1,024\n",
      "             ReLU-21                  [-1, 512]               0\n",
      "          Dropout-22                  [-1, 512]               0\n",
      "           Linear-23                  [-1, 256]         131,328\n",
      "      BatchNorm1d-24                  [-1, 256]             512\n",
      "             ReLU-25                  [-1, 256]               0\n",
      "          Dropout-26                  [-1, 256]               0\n",
      "           Linear-27                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,236,362\n",
      "Trainable params: 1,236,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.85\n",
      "Params size (MB): 4.72\n",
      "Estimated Total Size (MB): 7.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example: [(filters, kernel_size, stride, padding)]\n",
    "conv_layers_config = [(64, 3, 1, 1),        # For 1st CNN-block\n",
    "                      (128*2, 3, 1, 'same'),      # For 2nd CNN-block\n",
    "                      (128*2, 3, 1, 'same'),      # For 3rd CNN-block\n",
    "                      (64*2, 3, 1, 'same')]      # For 4th CNN-block\n",
    "\n",
    "# Initialize the model with more CNN layers\n",
    "model = CNN_ModuleList(conv_layers_config=conv_layers_config, units1=512, units2=256).to('cpu')\n",
    "summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 16:53:39.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-165339\u001b[0m\n",
      "\u001b[32m2025-02-17 16:53:39.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:43<00:00,  9.03it/s]\n",
      "\u001b[32m2025-02-17 16:55:28.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4187 test 0.3111 metric ['0.8862']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:48<00:00,  8.64it/s]\n",
      "\u001b[32m2025-02-17 16:57:22.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.2732 test 0.2941 metric ['0.8907']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:44<00:00,  8.98it/s]\n",
      "\u001b[32m2025-02-17 16:59:12.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.2286 test 0.2321 metric ['0.9154']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:41<00:00,  9.21it/s]\n",
      "\u001b[32m2025-02-17 17:00:59.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.1994 test 0.2238 metric ['0.9222']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:47<00:00,  8.74it/s]\n",
      "\u001b[32m2025-02-17 17:02:52.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.1739 test 0.2433 metric ['0.9135']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:02:52.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2433.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:44<00:00,  8.97it/s]\n",
      "\u001b[32m2025-02-17 17:04:43.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 0.1545 test 0.2266 metric ['0.9260']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:04:43.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2266.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:46<00:00,  8.79it/s]\n",
      "\u001b[32m2025-02-17 17:06:36.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 0.1348 test 0.2629 metric ['0.9152']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:06:36.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2629.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:45<00:00,  8.90it/s]\n",
      "\u001b[32m2025-02-17 17:08:28.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 0.1178 test 0.2712 metric ['0.9178']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:08:28.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2712.Counter 4/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:48<00:00,  8.67it/s]\n",
      "\u001b[32m2025-02-17 17:10:23.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.1040 test 0.2437 metric ['0.9273']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:10:23.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2437.Counter 5/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [01:47<00:00,  8.72it/s]\n",
      "\u001b[32m2025-02-17 17:12:17.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.0895 test 0.2376 metric ['0.9276']\u001b[0m\n",
      "\u001b[32m2025-02-17 17:12:17.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2238, current loss 0.2376.Counter 6/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [18:37<00:00, 111.74s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device='cpu',\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**The above result suggest that even after increasing the number of CNN layers we did not achieve significant performance boost. This new model took almsot double the time to train, but still only able to achieve the 92% accuracy. Hence, we can conclude that the we have maxed the performance of the model on the `FashionMNIST` dataset.**\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
