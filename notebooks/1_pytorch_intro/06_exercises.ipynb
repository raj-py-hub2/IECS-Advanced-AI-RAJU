{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "\n",
    "## 0. Setup your own repo\n",
    "- Setting up a repo is often repetitive. That's why you can use what are called 'cookiecutters', providing you with a template structure with some basic folders and files already set up for you. You don't have to use one, and can do it by hand, but have a look and maybe you think it is helpful.\n",
    "    - You could use the `cookiecutter` command that is preinstalled on your VM to create a repo, see https://github.com/raoulg/datascience-cookiecutter for details. I made this one myself, because I ended up editing the cookiecutter I was using.\n",
    "    - Another project is this one https://github.com/drivendata/cookiecutter-data-science , also intended for data science projects\n",
    "    - more general cookiecutters are shipped with tools like [pdm](https://pdm-project.org/latest/) and [rye](https://rye-up.com/); starting a project with `pdm init` or `rye init` (see docs for details) will provide you with some minimal structure, and there is the option to provide your own template with pdm (see [pdm template](https://pdm-project.org/latest/usage/template/))\n",
    "- push your own repo to github. Use `IECS-Advanced-AI-{yourname}` as a format, eg `IECS-Advanced-AI-SarmientoC`.\n",
    "- Invite (clein2312; https://github.com/Clein2312) as a collaborator to your repo.\n",
    "- make the excercises 1-5 below in your repo, and push them to github.\n",
    "\n",
    "Tips:\n",
    "- Commit often (every 30 minutes or so) \n",
    "- really, commit often. commiting and pushing your work is the best way to make sure your work is saved properly.\n",
    "- Commit groups of files that are related to each other. If you have more files, commit them separately.\n",
    "- Write commit messages that are descriptive and informative. \"lesson 1\", \"changes\" or \"commit\" are bad commit messages; \"added excercise 2\" is better, \"[exercise 2] added __len__ to Dataset class\" is even better.\n",
    "- Use `pdm` or `rye` to add dependencies. `mads_datasets` and `mltrainer` should cover a lot of what you need; don't blindly copy-paste all dependencies but keep your `pyproject.toml` as clean as possible.\n",
    "\n",
    "At some point, you will get a grade for the excercises that is 0 (not good enough), 1 (good enough) or 2 (excellent).\n",
    "I will look for both form and correctness to determine your grade.\n",
    "The result be incorporated into your final grade for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 3D Tensor dataset\n",
    "- Create a random 3D tensor dataset with `torch`\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** In the following code we created a `random` tensor of shape `(32, 10)`, which can be think of as random data with 32 observations with 10 features.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.rand(32, 10)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build your own `DataSet` class, such that you can get a 3D tensor and a label (which can be a random 0 or 1)\n",
    "See notebook 03_dataloader for details on how to create a custom dataset. See 01_tensors and the torch documentation how to create random tensors.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Solution:** In the following code we defined a custom dataloader with the name of `DataSet`. This dataloader should have the minmum 3 functions; `__init__` (to initialize the dataset), `__len__` (returns the total lenght of the dataset), and `__getitem__` (returns the data and target values when iterated over the initialized dataset). The usability will be discussed in the next section of datastreamers.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Tuple, List\n",
    "class DataSet:\n",
    "    def __init__(self, data, targets) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    # It will iterate the data and targets provided in the initilization phase\n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datastreamers\n",
    "Study the `BaseDatastreamer` in `03_dataloader` and use it with your own dataset, such that you get a datastreamer that will keep on giving you new batches of data when you call `next()` or loop over it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Solution:** In order to get the `BaseDatastreamer` working to call the next batch from the function `next()`, we first need to create the random dataset. As the `BaseDatastreamer` requires the dataset to be in a `tuple`, we will append the `X` and `y` together in a tuple. \n",
    "\n",
    "Lets suppose we a image dataset, and each image shape is `(3, 128, 128)`. In total we have eaxactly `500` images. The iteration will be processed by our preiously built `DataSet` class.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(500, 3, 256, 256)    # 500 image dataset\n",
    "y = torch.rand(500,)                # 500 target values\n",
    "\n",
    "# Our custom data holds all the 500 images and targets\n",
    "customData = DataSet(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 256, 256]), tensor(0.8866), 500)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = customData[1]\n",
    "X.shape, y, len(customData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# this barch process is required by BaseDatastreamer to iterate in batches\n",
    "# this will stack the batches of image and targets\n",
    "def batch_processor(batch):\n",
    "    X, Y = zip(*batch)\n",
    "    return np.stack(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "\n",
    "# this will create a streamer iterate over the dataset\n",
    "streamer = BaseDatastreamer(\n",
    "    dataset=customData,\n",
    "    batchsize=32,\n",
    "    preprocessor=batch_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**The `next()` function will give the next new batch from the dataset to train.**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 3, 256, 256), (32,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = streamer.stream()\n",
    "X, y = next(gen)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tune the network\n",
    "For this exercise we won't build upon the previous exercises, but instead will use the Fashion dataset.\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "#### Note: \n",
    "**This code requires specific version of the libraries `mltrainer==0.1.129` and `gin-config==0.5.0`**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='model.gin', imports=['gin.torch.external_configurables'], includes=[])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gin.external_configurable(imagemodels.NeuralNetwork, module=\"imagemodels\")\n",
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "**Note:** The above warning is due to library mismatch. This is an depreceation warning and it will not impact in the results of our experiments.\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `gin-config` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "\n",
    "The `model.gin` file is a simple file that will try to load parameters for funcitons that are already imported. \n",
    "\n",
    "So, if you wouldnt have imported train_model, the ginfile would not be able to parse settings for train_model.trainloop and will give an error.\n",
    "\n",
    "We can print all the settings that are operational with `gin.operative_config_str()` once we have loaded the functions to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 14:18:02.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:02.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessor = BasePreprocessor()\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import gin.torch.external_configurables\n",
      "\n",
      "# Parameters for NeuralNetwork:\n",
      "# ==============================================================================\n",
      "NeuralNetwork.num_classes = 10\n",
      "NeuralNetwork.units1 = 512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gin.config_str())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big advantage is that we can save this config as a file; that way it is easy to track what you changed during your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 14:18:02.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141802\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:02.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 283.34it/s]\n",
      "\u001b[32m2025-02-17 14:18:06.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5121 test 0.4127 metric ['0.8524']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 234.18it/s]\n",
      "\u001b[32m2025-02-17 14:18:10.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3668 test 0.3779 metric ['0.8679']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 230.82it/s]\n",
      "\u001b[32m2025-02-17 14:18:14.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3282 test 0.3487 metric ['0.8745']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 237.40it/s]\n",
      "\u001b[32m2025-02-17 14:18:19.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3048 test 0.3509 metric ['0.8773']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:19.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3487, current loss 0.3509.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 231.10it/s]\n",
      "\u001b[32m2025-02-17 14:18:23.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2893 test 0.3523 metric ['0.8752']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:23.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3487, current loss 0.3523.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:20<00:00,  4.18s/it]\n",
      "\u001b[32m2025-02-17 14:18:23.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141823\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:23.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 266.21it/s]\n",
      "\u001b[32m2025-02-17 14:18:27.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5226 test 0.4059 metric ['0.8566']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 283.82it/s]\n",
      "\u001b[32m2025-02-17 14:18:31.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3718 test 0.3912 metric ['0.8568']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 258.03it/s]\n",
      "\u001b[32m2025-02-17 14:18:34.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3300 test 0.3566 metric ['0.8727']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 255.30it/s]\n",
      "\u001b[32m2025-02-17 14:18:38.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3082 test 0.3550 metric ['0.8739']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.07it/s]\n",
      "\u001b[32m2025-02-17 14:18:43.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2898 test 0.3490 metric ['0.8734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:19<00:00,  3.91s/it]\n",
      "\u001b[32m2025-02-17 14:18:43.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141843\u001b[0m\n",
      "\u001b[32m2025-02-17 14:18:43.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 315.99it/s]\n",
      "\u001b[32m2025-02-17 14:18:46.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5352 test 0.4395 metric ['0.8422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 310.77it/s]\n",
      "\u001b[32m2025-02-17 14:18:49.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3780 test 0.3791 metric ['0.8632']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 291.14it/s]\n",
      "\u001b[32m2025-02-17 14:18:53.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3382 test 0.3788 metric ['0.8654']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 277.73it/s]\n",
      "\u001b[32m2025-02-17 14:18:56.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3150 test 0.3647 metric ['0.8693']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 275.05it/s]\n",
      "\u001b[32m2025-02-17 14:19:00.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2936 test 0.3459 metric ['0.8732']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:17<00:00,  3.50s/it]\n",
      "\u001b[32m2025-02-17 14:19:00.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141900\u001b[0m\n",
      "\u001b[32m2025-02-17 14:19:00.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 331.07it/s]\n",
      "\u001b[32m2025-02-17 14:19:03.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5281 test 0.4466 metric ['0.8365']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 305.56it/s]\n",
      "\u001b[32m2025-02-17 14:19:07.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3764 test 0.3886 metric ['0.8611']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 296.83it/s]\n",
      "\u001b[32m2025-02-17 14:19:10.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3378 test 0.3698 metric ['0.8634']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 274.32it/s]\n",
      "\u001b[32m2025-02-17 14:19:14.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3123 test 0.3582 metric ['0.8749']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 281.77it/s]\n",
      "\u001b[32m2025-02-17 14:19:17.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2950 test 0.3501 metric ['0.8764']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:17<00:00,  3.45s/it]\n",
      "\u001b[32m2025-02-17 14:19:17.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141917\u001b[0m\n",
      "\u001b[32m2025-02-17 14:19:17.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 360.51it/s]\n",
      "\u001b[32m2025-02-17 14:19:20.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5435 test 0.4701 metric ['0.8317']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 337.06it/s]\n",
      "\u001b[32m2025-02-17 14:19:23.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3835 test 0.4068 metric ['0.8516']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 341.05it/s]\n",
      "\u001b[32m2025-02-17 14:19:26.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3440 test 0.3975 metric ['0.8584']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 337.57it/s]\n",
      "\u001b[32m2025-02-17 14:19:30.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3177 test 0.3663 metric ['0.8661']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 329.22it/s]\n",
      "\u001b[32m2025-02-17 14:19:33.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3018 test 0.3590 metric ['0.8728']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:15<00:00,  3.04s/it]\n",
      "\u001b[32m2025-02-17 14:19:33.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141933\u001b[0m\n",
      "\u001b[32m2025-02-17 14:19:33.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 355.74it/s]\n",
      "\u001b[32m2025-02-17 14:19:36.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5576 test 0.4413 metric ['0.8412']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 353.27it/s]\n",
      "\u001b[32m2025-02-17 14:19:39.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3879 test 0.3936 metric ['0.8567']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 402.52it/s]\n",
      "\u001b[32m2025-02-17 14:19:41.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3478 test 0.3751 metric ['0.8649']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 383.29it/s]\n",
      "\u001b[32m2025-02-17 14:19:44.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3247 test 0.3587 metric ['0.8695']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 354.39it/s]\n",
      "\u001b[32m2025-02-17 14:19:47.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3046 test 0.3568 metric ['0.8722']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:14<00:00,  2.81s/it]\n",
      "\u001b[32m2025-02-17 14:19:47.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-141947\u001b[0m\n",
      "\u001b[32m2025-02-17 14:19:47.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 351.50it/s]\n",
      "\u001b[32m2025-02-17 14:19:50.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5480 test 0.4881 metric ['0.8305']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 365.55it/s]\n",
      "\u001b[32m2025-02-17 14:19:53.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3858 test 0.4085 metric ['0.8546']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 378.14it/s]\n",
      "\u001b[32m2025-02-17 14:19:55.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3464 test 0.3689 metric ['0.8635']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 370.00it/s]\n",
      "\u001b[32m2025-02-17 14:19:58.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3265 test 0.3636 metric ['0.8716']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 363.30it/s]\n",
      "\u001b[32m2025-02-17 14:20:01.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3095 test 0.3520 metric ['0.8733']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:14<00:00,  2.84s/it]\n",
      "\u001b[32m2025-02-17 14:20:01.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-142001\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:01.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 402.13it/s]\n",
      "\u001b[32m2025-02-17 14:20:03.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5621 test 0.4335 metric ['0.8435']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 392.83it/s]\n",
      "\u001b[32m2025-02-17 14:20:06.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3951 test 0.4104 metric ['0.8498']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 394.03it/s]\n",
      "\u001b[32m2025-02-17 14:20:09.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3537 test 0.3854 metric ['0.8583']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 363.28it/s]\n",
      "\u001b[32m2025-02-17 14:20:12.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3326 test 0.3595 metric ['0.8699']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 387.72it/s]\n",
      "\u001b[32m2025-02-17 14:20:14.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3136 test 0.3707 metric ['0.8631']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:14.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3595, current loss 0.3707.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.69s/it]\n",
      "\u001b[32m2025-02-17 14:20:14.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/20250217-142014\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:14.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 388.37it/s]\n",
      "\u001b[32m2025-02-17 14:20:17.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5937 test 0.4463 metric ['0.8372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 385.71it/s]\n",
      "\u001b[32m2025-02-17 14:20:20.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4124 test 0.4139 metric ['0.8527']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 385.49it/s]\n",
      "\u001b[32m2025-02-17 14:20:22.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3711 test 0.4040 metric ['0.8556']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 373.17it/s]\n",
      "\u001b[32m2025-02-17 14:20:25.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3463 test 0.3795 metric ['0.8597']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 365.18it/s]\n",
      "\u001b[32m2025-02-17 14:20:28.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3277 test 0.3603 metric ['0.8695']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        gin.bind_parameter(\"NeuralNetwork.units1\", unit1)\n",
    "        gin.bind_parameter(\"NeuralNetwork.units2\", unit2)\n",
    "\n",
    "        model = imagemodels.NeuralNetwork()\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=models` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Experiment with things like:\n",
    "\n",
    "- changing the amount of units1 and units2 to values between 16 and 1024. Use factors of 2: 16, 32, 64, etc.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** units1 and unist2 as factors of 2 (16 to 1024) are [16, 32, 64, 128, 256, 512, 1024]. By keeping the computational complexity of these, we limited the search space to [64, 128, 256]. However, it can be changed later to have all the values.\n",
    "</font>\n",
    "\n",
    "- changing the batchsize to values between 4 and 128. Again, use factors of two.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** For the batch size value we keep all the values between 4 and 128 (by factor of 2), i.e. [4, 8, 16, 32, 64, 128].\n",
    "</font>\n",
    "\n",
    "- all your experiments are saved in the `modelslogs` directory, with a timestamp. Inside you find a saved_config.gin file, that \n",
    "contains all the settings for that experiment. The `events` file is what tensorboard will show.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** All experiemnts are saved within the `modelslogs` directory with the timestampe for example `experiment_20250215_123844`, inside you will find 2 files, `saved_config.gin` (contains experiemnt configuration) and `events` file (contains tensorboard logs during tarining for loss and accuracy values.)\n",
    "</font>\n",
    "\n",
    "- plot the result in a heatmap: units vs batchsize.\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** At the very end. The heatmap is plotted and explanation is provided for it.\n",
    "</font>\n",
    "\n",
    "- changing the learningrate to values between 1e-2 and 1e-5 \n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** For consistency among our experiments, we kept the learning rate value to 1e-5. Otherwise, we might see influence of learning rate on accuracy, however, our main goal is to see corelation between units vs. batchsize in terms of model accuracy.  \n",
    "</font>\n",
    "\n",
    "- changing the optimizer from SGD to one of the other available algoritms at [torch](https://pytorch.org/docs/stable/optim.html) (scroll down for the algorithms)\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "**Answer:** For the following experiments, we use the `Adam` optimizer. \n",
    "</font>\n",
    "\n",
    "A note on train_steps: this is a setting that determines how often you get an update. \n",
    "Because our complete dataset is 938 (60000 / 64) batches long, you will need 938 trainstep to cover the complete 60.000 images.\n",
    "\n",
    "This can actually be a bit confusion, because every value below 938 changes the meaning of `epoch` slightly, because one epoch is no longer\n",
    "the full dataset, but simply `trainstep` batches. Setting trainsteps to 100 means you need to wait twice as long before you get feedback on the performance,\n",
    "as compared to trainsteps=50. You will also see that settings trainsteps to 100 improves the learning, but that is simply because the model has seen twice as \n",
    "much examples as compared to trainsteps=50.\n",
    "\n",
    "This implies that it is not usefull to compare trainsteps=50 and trainsteps=100, because setting it to 100 will always be better.\n",
    "Just pick an amount, and adjust your number of epochs accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='green'>\n",
    "\n",
    "### Experiments\n",
    "\n",
    "##### Experiemnt with the other model parameters to inspect the change in final output results.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "You can use `list` to write each parameter individually. This way we can see what we are working on.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# units1 and units2 as factors of 2 (16 to 1024) are [16, 32, 64, 128, 256, 512, 1024]\n",
    "# choosing only few to have the intiuation of what is the effect of these on batch_sizes\n",
    "# however you can change have larger space to see the results\n",
    "units_values = [64, 128, 256]\n",
    "\n",
    "# batch sizes as factors of 2 (4 to 128)\n",
    "batch_sizes = [4, 8, 16, 32, 64, 128]\n",
    "\n",
    "optimizer = optim.Adam  # Different optimizer other than SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 128, 256]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = BasePreprocessor()\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "# Other functions will be initialized in the Experiment section "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='green'>\n",
    "\n",
    "Following is the helper function which will help to load the tensorbaord values in a list. We will use it later to store the accuracy for that training iteration. You can load the tensorboard as defined previously to confirm under what name the `accuracy` of the model is being logged. By inspecting the tensorboard, it has seen that we get the accuracy under the tag of `metric\\Accuracy` \n",
    "\n",
    "**Note: (if you want to use this helper function somewhere else, please change this tag to match your tensorboad logs.)**\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function to load tensorboard values\n",
    "# you can also write it in another .py script and load it in here to keep your code clean.\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "def load_tensorboard_data(logdir):\n",
    "    \"\"\"\n",
    "    Load TensorBoard data from the specified log directory.\n",
    "    Returns a dictionary of metrics and their values over epochs.\n",
    "    \"\"\"\n",
    "    # Initialize EventAccumulator\n",
    "    event_acc = EventAccumulator(logdir)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    # Extract scalar data\n",
    "    metrics = []\n",
    "    for tag in event_acc.Tags()[\"scalars\"]:\n",
    "        if tag == 'metric/Accuracy':\n",
    "            events = event_acc.Scalars(tag)\n",
    "            metrics = [event.value for event in events]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "Each model needs to be trained and evaluated to determine which combination of hyperparameters performs best. We use accuracy as the metric to compare different configurations. So, we will store the final accuracy of each experiment in `results` list.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For heatmap (units vs. batchsize)\n",
    "import numpy as np\n",
    "results = np.zeros((len(units_values), (len(batch_sizes))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "Lets do the experiment on all the combination of the `unit1` and `unit2`. The values of these variabels is defined previously. The results for each combination will be stored to built the heatmap.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 14:20:28.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:28.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:28.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142028\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:28.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142028/20250217-142028\u001b[0m\n",
      "\u001b[32m2025-02-17 14:20:28.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:15<00:00, 937.77it/s]\n",
      "\u001b[32m2025-02-17 14:20:45.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4943 test 0.4550 metric ['0.8336']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 900.92it/s]\n",
      "\u001b[32m2025-02-17 14:21:02.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3833 test 0.4618 metric ['0.8373']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:02.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.4550, current loss 0.4618.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 912.91it/s]\n",
      "\u001b[32m2025-02-17 14:21:19.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3550 test 0.3900 metric ['0.8587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 902.37it/s]\n",
      "\u001b[32m2025-02-17 14:21:37.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3385 test 0.4126 metric ['0.8587']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:37.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3900, current loss 0.4126.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 910.33it/s]\n",
      "\u001b[32m2025-02-17 14:21:54.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3244 test 0.4331 metric ['0.8576']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:54.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3900, current loss 0.4331.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:25<00:00, 17.13s/it]\n",
      "\u001b[32m2025-02-17 14:21:54.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:54.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:54.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142154\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:54.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142154/20250217-142154\u001b[0m\n",
      "\u001b[32m2025-02-17 14:21:54.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 894.07it/s]\n",
      "\u001b[32m2025-02-17 14:22:03.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5043 test 0.4246 metric ['0.8462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 793.31it/s]\n",
      "\u001b[32m2025-02-17 14:22:13.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3729 test 0.4112 metric ['0.8541']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 845.94it/s]\n",
      "\u001b[32m2025-02-17 14:22:22.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3423 test 0.3735 metric ['0.8628']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 822.31it/s]\n",
      "\u001b[32m2025-02-17 14:22:32.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3203 test 0.3664 metric ['0.8635']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 822.00it/s]\n",
      "\u001b[32m2025-02-17 14:22:41.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3069 test 0.3734 metric ['0.8666']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:22:41.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3664, current loss 0.3734.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:47<00:00,  9.48s/it]\n",
      "\u001b[32m2025-02-17 14:22:41.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:22:41.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:22:41.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142241\u001b[0m\n",
      "\u001b[32m2025-02-17 14:22:41.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142241/20250217-142241\u001b[0m\n",
      "\u001b[32m2025-02-17 14:22:41.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 755.37it/s]\n",
      "\u001b[32m2025-02-17 14:22:47.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5106 test 0.4229 metric ['0.8446']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 766.66it/s]\n",
      "\u001b[32m2025-02-17 14:22:52.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3741 test 0.3899 metric ['0.8577']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 717.49it/s]\n",
      "\u001b[32m2025-02-17 14:22:57.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3426 test 0.3627 metric ['0.8666']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 694.00it/s]\n",
      "\u001b[32m2025-02-17 14:23:03.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3204 test 0.3616 metric ['0.8699']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 700.67it/s]\n",
      "\u001b[32m2025-02-17 14:23:09.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3058 test 0.3833 metric ['0.8618']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:09.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3616, current loss 0.3833.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:27<00:00,  5.52s/it]\n",
      "\u001b[32m2025-02-17 14:23:09.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:09.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:09.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142309\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:09.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142309/20250217-142309\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:09.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 548.36it/s]\n",
      "\u001b[32m2025-02-17 14:23:13.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5488 test 0.4456 metric ['0.8384']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 556.63it/s]\n",
      "\u001b[32m2025-02-17 14:23:16.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3896 test 0.4020 metric ['0.8552']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 543.95it/s]\n",
      "\u001b[32m2025-02-17 14:23:20.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3513 test 0.3707 metric ['0.8652']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 557.89it/s]\n",
      "\u001b[32m2025-02-17 14:23:24.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3272 test 0.3863 metric ['0.8585']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:24.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3707, current loss 0.3863.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 520.56it/s]\n",
      "\u001b[32m2025-02-17 14:23:28.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3101 test 0.3563 metric ['0.8704']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:18<00:00,  3.77s/it]\n",
      "\u001b[32m2025-02-17 14:23:28.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:28.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:28.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142328\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:28.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142328/20250217-142328\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:28.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 388.49it/s]\n",
      "\u001b[32m2025-02-17 14:23:30.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5782 test 0.4458 metric ['0.8448']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 377.19it/s]\n",
      "\u001b[32m2025-02-17 14:23:33.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4080 test 0.4098 metric ['0.8544']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 393.92it/s]\n",
      "\u001b[32m2025-02-17 14:23:36.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3665 test 0.3956 metric ['0.8573']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 397.86it/s]\n",
      "\u001b[32m2025-02-17 14:23:38.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3418 test 0.3682 metric ['0.8708']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 409.64it/s]\n",
      "\u001b[32m2025-02-17 14:23:41.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3258 test 0.3851 metric ['0.8606']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:41.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3682, current loss 0.3851.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.63s/it]\n",
      "\u001b[32m2025-02-17 14:23:41.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:41.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:41.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142341\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:41.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142341/20250217-142341\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:41.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 235.66it/s]\n",
      "\u001b[32m2025-02-17 14:23:43.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.6696 test 0.4868 metric ['0.8270']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 256.91it/s]\n",
      "\u001b[32m2025-02-17 14:23:45.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4323 test 0.4270 metric ['0.8479']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 251.36it/s]\n",
      "\u001b[32m2025-02-17 14:23:47.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3873 test 0.4225 metric ['0.8492']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 241.20it/s]\n",
      "\u001b[32m2025-02-17 14:23:50.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3663 test 0.3925 metric ['0.8575']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 239.25it/s]\n",
      "\u001b[32m2025-02-17 14:23:52.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3474 test 0.3876 metric ['0.8610']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:10<00:00,  2.17s/it]\n",
      "\u001b[32m2025-02-17 14:23:52.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:52.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:52.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142352\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:52.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142352/20250217-142352\u001b[0m\n",
      "\u001b[32m2025-02-17 14:23:52.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 921.04it/s]\n",
      "\u001b[32m2025-02-17 14:24:09.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4891 test 0.4382 metric ['0.8430']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 907.47it/s]\n",
      "\u001b[32m2025-02-17 14:24:26.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3820 test 0.4090 metric ['0.8537']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:17<00:00, 873.76it/s]\n",
      "\u001b[32m2025-02-17 14:24:44.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3540 test 0.4039 metric ['0.8557']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 906.38it/s]\n",
      "\u001b[32m2025-02-17 14:25:01.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3389 test 0.3714 metric ['0.8672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:17<00:00, 881.34it/s]\n",
      "\u001b[32m2025-02-17 14:25:19.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3282 test 0.3745 metric ['0.8687']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:25:19.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3714, current loss 0.3745.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:26<00:00, 17.39s/it]\n",
      "\u001b[32m2025-02-17 14:25:19.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:25:19.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:25:19.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142519\u001b[0m\n",
      "\u001b[32m2025-02-17 14:25:19.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142519/20250217-142519\u001b[0m\n",
      "\u001b[32m2025-02-17 14:25:19.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 882.44it/s]\n",
      "\u001b[32m2025-02-17 14:25:28.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4915 test 0.4370 metric ['0.8435']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 852.41it/s]\n",
      "\u001b[32m2025-02-17 14:25:37.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3759 test 0.4047 metric ['0.8550']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 876.54it/s]\n",
      "\u001b[32m2025-02-17 14:25:46.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3430 test 0.3845 metric ['0.8690']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 869.59it/s]\n",
      "\u001b[32m2025-02-17 14:25:55.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3213 test 0.3731 metric ['0.8626']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 845.44it/s]\n",
      "\u001b[32m2025-02-17 14:26:05.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3060 test 0.4025 metric ['0.8575']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:05.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3731, current loss 0.4025.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:45<00:00,  9.15s/it]\n",
      "\u001b[32m2025-02-17 14:26:05.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:05.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:05.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142605\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:05.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142605/20250217-142605\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:05.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 764.40it/s]\n",
      "\u001b[32m2025-02-17 14:26:10.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5020 test 0.4362 metric ['0.8435']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 728.40it/s]\n",
      "\u001b[32m2025-02-17 14:26:15.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3724 test 0.3917 metric ['0.8578']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 686.33it/s]\n",
      "\u001b[32m2025-02-17 14:26:21.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3364 test 0.3792 metric ['0.8642']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 676.67it/s]\n",
      "\u001b[32m2025-02-17 14:26:27.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3151 test 0.3597 metric ['0.8683']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 728.47it/s]\n",
      "\u001b[32m2025-02-17 14:26:32.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2978 test 0.3479 metric ['0.8750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:27<00:00,  5.57s/it]\n",
      "\u001b[32m2025-02-17 14:26:32.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:32.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:32.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142632\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:32.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142632/20250217-142632\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:32.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 561.20it/s]\n",
      "\u001b[32m2025-02-17 14:26:36.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5256 test 0.4580 metric ['0.8312']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 538.94it/s]\n",
      "\u001b[32m2025-02-17 14:26:40.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3807 test 0.3814 metric ['0.8627']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 505.65it/s]\n",
      "\u001b[32m2025-02-17 14:26:44.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3426 test 0.3749 metric ['0.8618']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 498.55it/s]\n",
      "\u001b[32m2025-02-17 14:26:48.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3218 test 0.3694 metric ['0.8668']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 502.32it/s]\n",
      "\u001b[32m2025-02-17 14:26:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3050 test 0.3652 metric ['0.8658']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:19<00:00,  3.90s/it]\n",
      "\u001b[32m2025-02-17 14:26:52.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:52.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:52.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142652\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:52.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142652/20250217-142652\u001b[0m\n",
      "\u001b[32m2025-02-17 14:26:52.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 387.54it/s]\n",
      "\u001b[32m2025-02-17 14:26:55.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5621 test 0.4515 metric ['0.8376']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 414.34it/s]\n",
      "\u001b[32m2025-02-17 14:26:57.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3979 test 0.4124 metric ['0.8524']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 349.75it/s]\n",
      "\u001b[32m2025-02-17 14:27:00.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3570 test 0.3923 metric ['0.8571']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 362.20it/s]\n",
      "\u001b[32m2025-02-17 14:27:03.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3349 test 0.3761 metric ['0.8645']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 360.95it/s]\n",
      "\u001b[32m2025-02-17 14:27:06.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3171 test 0.3631 metric ['0.8720']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.78s/it]\n",
      "\u001b[32m2025-02-17 14:27:06.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:06.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:06.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142706\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:06.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142706/20250217-142706\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:06.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 245.26it/s]\n",
      "\u001b[32m2025-02-17 14:27:08.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.6253 test 0.4586 metric ['0.8371']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 230.26it/s]\n",
      "\u001b[32m2025-02-17 14:27:10.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4147 test 0.4229 metric ['0.8482']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 214.91it/s]\n",
      "\u001b[32m2025-02-17 14:27:13.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3708 test 0.3985 metric ['0.8578']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 251.33it/s]\n",
      "\u001b[32m2025-02-17 14:27:15.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3485 test 0.3815 metric ['0.8635']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 235.11it/s]\n",
      "\u001b[32m2025-02-17 14:27:17.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3310 test 0.3728 metric ['0.8670']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:11<00:00,  2.24s/it]\n",
      "\u001b[32m2025-02-17 14:27:17.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:17.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:17.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142717\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:17.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142717/20250217-142717\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:17.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:18<00:00, 808.98it/s]\n",
      "\u001b[32m2025-02-17 14:27:36.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4944 test 0.4744 metric ['0.8296']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:18<00:00, 800.22it/s]\n",
      "\u001b[32m2025-02-17 14:27:56.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3851 test 0.5021 metric ['0.8191']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:27:56.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.4744, current loss 0.5021.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 778.24it/s]\n",
      "\u001b[32m2025-02-17 14:28:16.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3599 test 0.4171 metric ['0.8489']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 751.95it/s]\n",
      "\u001b[32m2025-02-17 14:28:37.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3430 test 0.3923 metric ['0.8587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 764.03it/s]\n",
      "\u001b[32m2025-02-17 14:28:57.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3333 test 0.3794 metric ['0.8682']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:39<00:00, 19.93s/it]\n",
      "\u001b[32m2025-02-17 14:28:57.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:28:57.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:28:57.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142857\u001b[0m\n",
      "\u001b[32m2025-02-17 14:28:57.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142857/20250217-142857\u001b[0m\n",
      "\u001b[32m2025-02-17 14:28:57.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 906.90it/s]\n",
      "\u001b[32m2025-02-17 14:29:05.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4927 test 0.4417 metric ['0.8360']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 762.00it/s]\n",
      "\u001b[32m2025-02-17 14:29:16.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3793 test 0.4102 metric ['0.8487']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 841.11it/s]\n",
      "\u001b[32m2025-02-17 14:29:25.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3472 test 0.3959 metric ['0.8587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 805.60it/s]\n",
      "\u001b[32m2025-02-17 14:29:35.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3286 test 0.3955 metric ['0.8563']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 823.54it/s]\n",
      "\u001b[32m2025-02-17 14:29:44.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3147 test 0.4360 metric ['0.8448']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:29:44.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3955, current loss 0.4360.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:47<00:00,  9.52s/it]\n",
      "\u001b[32m2025-02-17 14:29:44.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:29:44.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:29:44.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_142944\u001b[0m\n",
      "\u001b[32m2025-02-17 14:29:44.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_142944/20250217-142944\u001b[0m\n",
      "\u001b[32m2025-02-17 14:29:44.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 796.00it/s]\n",
      "\u001b[32m2025-02-17 14:29:49.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4894 test 0.4515 metric ['0.8306']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 743.12it/s]\n",
      "\u001b[32m2025-02-17 14:29:55.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3684 test 0.3784 metric ['0.8613']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 717.62it/s]\n",
      "\u001b[32m2025-02-17 14:30:00.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3358 test 0.3801 metric ['0.8616']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:00.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3784, current loss 0.3801.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 726.09it/s]\n",
      "\u001b[32m2025-02-17 14:30:06.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3142 test 0.3469 metric ['0.8738']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 735.88it/s]\n",
      "\u001b[32m2025-02-17 14:30:11.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2987 test 0.3804 metric ['0.8622']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:11.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3469, current loss 0.3804.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:26<00:00,  5.36s/it]\n",
      "\u001b[32m2025-02-17 14:30:11.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:11.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:11.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143011\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:11.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143011/20250217-143011\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:11.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 700.92it/s]\n",
      "\u001b[32m2025-02-17 14:30:14.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5136 test 0.4343 metric ['0.8407']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 592.85it/s]\n",
      "\u001b[32m2025-02-17 14:30:18.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3757 test 0.3972 metric ['0.8535']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 639.60it/s]\n",
      "\u001b[32m2025-02-17 14:30:21.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3380 test 0.3716 metric ['0.8633']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 621.53it/s]\n",
      "\u001b[32m2025-02-17 14:30:24.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3181 test 0.3491 metric ['0.8755']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 554.70it/s]\n",
      "\u001b[32m2025-02-17 14:30:28.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2971 test 0.3779 metric ['0.8621']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:28.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3491, current loss 0.3779.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:16<00:00,  3.29s/it]\n",
      "\u001b[32m2025-02-17 14:30:28.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:28.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:28.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143028\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:28.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143028/20250217-143028\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:28.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 495.49it/s]\n",
      "\u001b[32m2025-02-17 14:30:30.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5480 test 0.4314 metric ['0.8432']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 446.30it/s]\n",
      "\u001b[32m2025-02-17 14:30:32.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3778 test 0.3867 metric ['0.8591']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 507.77it/s]\n",
      "\u001b[32m2025-02-17 14:30:34.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3402 test 0.3753 metric ['0.8634']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 484.68it/s]\n",
      "\u001b[32m2025-02-17 14:30:36.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3191 test 0.3600 metric ['0.8682']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 467.90it/s]\n",
      "\u001b[32m2025-02-17 14:30:39.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3013 test 0.3372 metric ['0.8777']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:10<00:00,  2.18s/it]\n",
      "\u001b[32m2025-02-17 14:30:39.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:39.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:39.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143039\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:39.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143039/20250217-143039\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:39.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 299.36it/s]\n",
      "\u001b[32m2025-02-17 14:30:40.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5977 test 0.4508 metric ['0.8407']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 291.79it/s]\n",
      "\u001b[32m2025-02-17 14:30:42.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4065 test 0.4272 metric ['0.8399']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 300.06it/s]\n",
      "\u001b[32m2025-02-17 14:30:44.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3685 test 0.3891 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 289.59it/s]\n",
      "\u001b[32m2025-02-17 14:30:46.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3408 test 0.3695 metric ['0.8654']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 294.35it/s]\n",
      "\u001b[32m2025-02-17 14:30:48.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3185 test 0.3631 metric ['0.8697']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.78s/it]\n",
      "\u001b[32m2025-02-17 14:30:48.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:48.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:48.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143048\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:48.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143048/20250217-143048\u001b[0m\n",
      "\u001b[32m2025-02-17 14:30:48.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:14<00:00, 1030.64it/s]\n",
      "\u001b[32m2025-02-17 14:31:03.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4914 test 0.4206 metric ['0.8483']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:14<00:00, 1013.46it/s]\n",
      "\u001b[32m2025-02-17 14:31:18.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3776 test 0.3981 metric ['0.8602']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:14<00:00, 1006.15it/s]\n",
      "\u001b[32m2025-02-17 14:31:34.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3484 test 0.4257 metric ['0.8504']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:31:34.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3981, current loss 0.4257.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:15<00:00, 986.64it/s]\n",
      "\u001b[32m2025-02-17 14:31:50.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3299 test 0.3669 metric ['0.8692']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:15<00:00, 978.16it/s] \n",
      "\u001b[32m2025-02-17 14:32:06.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3165 test 0.3715 metric ['0.8649']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:06.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3669, current loss 0.3715.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:18<00:00, 15.64s/it]\n",
      "\u001b[32m2025-02-17 14:32:06.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:06.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:06.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143206\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:06.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143206/20250217-143206\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:06.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:07<00:00, 968.81it/s]\n",
      "\u001b[32m2025-02-17 14:32:14.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4861 test 0.4026 metric ['0.8501']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 908.58it/s]\n",
      "\u001b[32m2025-02-17 14:32:23.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3684 test 0.3852 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 922.66it/s]\n",
      "\u001b[32m2025-02-17 14:32:31.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3379 test 0.3725 metric ['0.8606']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 928.08it/s]\n",
      "\u001b[32m2025-02-17 14:32:40.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3179 test 0.3660 metric ['0.8717']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 905.45it/s]\n",
      "\u001b[32m2025-02-17 14:32:49.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3024 test 0.3593 metric ['0.8708']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:42<00:00,  8.58s/it]\n",
      "\u001b[32m2025-02-17 14:32:49.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:49.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:49.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143249\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:49.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143249/20250217-143249\u001b[0m\n",
      "\u001b[32m2025-02-17 14:32:49.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 891.13it/s]\n",
      "\u001b[32m2025-02-17 14:32:53.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5043 test 0.4275 metric ['0.8478']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 866.13it/s]\n",
      "\u001b[32m2025-02-17 14:32:58.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3712 test 0.3897 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 735.17it/s]\n",
      "\u001b[32m2025-02-17 14:33:03.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3362 test 0.3972 metric ['0.8551']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:03.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3897, current loss 0.3972.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 683.16it/s]\n",
      "\u001b[32m2025-02-17 14:33:09.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3142 test 0.3586 metric ['0.8713']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 718.19it/s]\n",
      "\u001b[32m2025-02-17 14:33:15.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2970 test 0.3625 metric ['0.8682']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:15.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3586, current loss 0.3625.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:26<00:00,  5.23s/it]\n",
      "\u001b[32m2025-02-17 14:33:15.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:15.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:15.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143315\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:15.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143315/20250217-143315\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:15.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 695.72it/s]\n",
      "\u001b[32m2025-02-17 14:33:18.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5267 test 0.4191 metric ['0.8485']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 638.66it/s]\n",
      "\u001b[32m2025-02-17 14:33:21.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3793 test 0.4186 metric ['0.8511']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 633.12it/s]\n",
      "\u001b[32m2025-02-17 14:33:24.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3410 test 0.3784 metric ['0.8626']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 557.26it/s]\n",
      "\u001b[32m2025-02-17 14:33:28.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3177 test 0.3623 metric ['0.8655']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 517.49it/s]\n",
      "\u001b[32m2025-02-17 14:33:32.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2998 test 0.3645 metric ['0.8669']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:32.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3623, current loss 0.3645.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:17<00:00,  3.41s/it]\n",
      "\u001b[32m2025-02-17 14:33:32.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:32.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:32.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143332\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:32.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143332/20250217-143332\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:32.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 481.91it/s]\n",
      "\u001b[32m2025-02-17 14:33:34.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5548 test 0.4441 metric ['0.8390']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 475.01it/s]\n",
      "\u001b[32m2025-02-17 14:33:36.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3919 test 0.4044 metric ['0.8528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 422.10it/s]\n",
      "\u001b[32m2025-02-17 14:33:39.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3522 test 0.3810 metric ['0.8617']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 439.60it/s]\n",
      "\u001b[32m2025-02-17 14:33:41.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3272 test 0.3644 metric ['0.8706']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 429.55it/s]\n",
      "\u001b[32m2025-02-17 14:33:44.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3075 test 0.3517 metric ['0.8726']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:11<00:00,  2.32s/it]\n",
      "\u001b[32m2025-02-17 14:33:44.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:44.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:44.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143344\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:44.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143344/20250217-143344\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:44.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 288.07it/s]\n",
      "\u001b[32m2025-02-17 14:33:45.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.6099 test 0.4541 metric ['0.8401']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 299.24it/s]\n",
      "\u001b[32m2025-02-17 14:33:47.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4121 test 0.4238 metric ['0.8519']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 295.73it/s]\n",
      "\u001b[32m2025-02-17 14:33:49.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3676 test 0.3887 metric ['0.8606']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 290.07it/s]\n",
      "\u001b[32m2025-02-17 14:33:51.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3406 test 0.3632 metric ['0.8710']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 294.71it/s]\n",
      "\u001b[32m2025-02-17 14:33:53.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3186 test 0.3598 metric ['0.8747']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:09<00:00,  1.81s/it]\n",
      "\u001b[32m2025-02-17 14:33:53.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:53.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:53.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143353\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143353/20250217-143353\u001b[0m\n",
      "\u001b[32m2025-02-17 14:33:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 914.55it/s]\n",
      "\u001b[32m2025-02-17 14:34:10.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4906 test 0.4464 metric ['0.8430']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 889.01it/s]\n",
      "\u001b[32m2025-02-17 14:34:27.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3825 test 0.4353 metric ['0.8458']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 884.41it/s]\n",
      "\u001b[32m2025-02-17 14:34:45.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3516 test 0.4139 metric ['0.8460']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:16<00:00, 894.04it/s]\n",
      "\u001b[32m2025-02-17 14:35:03.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3358 test 0.3808 metric ['0.8681']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:17<00:00, 872.67it/s]\n",
      "\u001b[32m2025-02-17 14:35:21.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3241 test 0.3956 metric ['0.8575']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:21.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3808, current loss 0.3956.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:27<00:00, 17.57s/it]\n",
      "\u001b[32m2025-02-17 14:35:21.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:21.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:21.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143521\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:21.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143521/20250217-143521\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:21.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:07<00:00, 939.82it/s]\n",
      "\u001b[32m2025-02-17 14:35:29.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4841 test 0.4184 metric ['0.8505']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 832.39it/s]\n",
      "\u001b[32m2025-02-17 14:35:38.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3693 test 0.3700 metric ['0.8681']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:08<00:00, 876.85it/s]\n",
      "\u001b[32m2025-02-17 14:35:47.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3361 test 0.3755 metric ['0.8621']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:47.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3700, current loss 0.3755.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 831.10it/s]\n",
      "\u001b[32m2025-02-17 14:35:57.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3151 test 0.3704 metric ['0.8672']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:35:57.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3700, current loss 0.3704.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:09<00:00, 832.33it/s]\n",
      "\u001b[32m2025-02-17 14:36:06.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2995 test 0.3579 metric ['0.8724']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:45<00:00,  9.18s/it]\n",
      "\u001b[32m2025-02-17 14:36:06.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:06.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:06.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143606\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:06.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143606/20250217-143606\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:06.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 771.75it/s]\n",
      "\u001b[32m2025-02-17 14:36:12.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4917 test 0.4190 metric ['0.8446']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 725.46it/s]\n",
      "\u001b[32m2025-02-17 14:36:17.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3702 test 0.3957 metric ['0.8575']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 636.58it/s]\n",
      "\u001b[32m2025-02-17 14:36:24.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3336 test 0.3624 metric ['0.8712']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 631.80it/s]\n",
      "\u001b[32m2025-02-17 14:36:30.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3131 test 0.3559 metric ['0.8698']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 673.22it/s]\n",
      "\u001b[32m2025-02-17 14:36:36.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2938 test 0.3527 metric ['0.8708']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:29<00:00,  5.85s/it]\n",
      "\u001b[32m2025-02-17 14:36:36.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:36.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:36.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143636\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:36.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143636/20250217-143636\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:36.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 664.07it/s]\n",
      "\u001b[32m2025-02-17 14:36:39.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5078 test 0.4179 metric ['0.8524']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:02<00:00, 634.93it/s]\n",
      "\u001b[32m2025-02-17 14:36:42.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3684 test 0.3839 metric ['0.8611']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 584.77it/s]\n",
      "\u001b[32m2025-02-17 14:36:46.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3328 test 0.3604 metric ['0.8726']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 564.09it/s]\n",
      "\u001b[32m2025-02-17 14:36:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3117 test 0.3815 metric ['0.8598']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3604, current loss 0.3815.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 552.04it/s]\n",
      "\u001b[32m2025-02-17 14:36:53.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2954 test 0.3592 metric ['0.8685']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:17<00:00,  3.42s/it]\n",
      "\u001b[32m2025-02-17 14:36:53.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:53.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:53.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143653\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:53.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143653/20250217-143653\u001b[0m\n",
      "\u001b[32m2025-02-17 14:36:53.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:01<00:00, 471.76it/s]\n",
      "\u001b[32m2025-02-17 14:36:55.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5567 test 0.4439 metric ['0.8426']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 452.86it/s]\n",
      "\u001b[32m2025-02-17 14:36:57.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3893 test 0.4107 metric ['0.8520']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 440.05it/s]\n",
      "\u001b[32m2025-02-17 14:37:00.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3468 test 0.3919 metric ['0.8579']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 415.02it/s]\n",
      "\u001b[32m2025-02-17 14:37:02.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3222 test 0.3561 metric ['0.8692']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 431.81it/s]\n",
      "\u001b[32m2025-02-17 14:37:05.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3027 test 0.3560 metric ['0.8728']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:11<00:00,  2.34s/it]\n",
      "\u001b[32m2025-02-17 14:37:05.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:05.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:05.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143705\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:05.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143705/20250217-143705\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:05.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 299.06it/s]\n",
      "\u001b[32m2025-02-17 14:37:06.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5960 test 0.4535 metric ['0.8392']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 287.91it/s]\n",
      "\u001b[32m2025-02-17 14:37:08.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4059 test 0.4202 metric ['0.8449']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 290.70it/s]\n",
      "\u001b[32m2025-02-17 14:37:10.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3629 test 0.3822 metric ['0.8638']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 265.21it/s]\n",
      "\u001b[32m2025-02-17 14:37:12.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3355 test 0.3629 metric ['0.8713']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 260.24it/s]\n",
      "\u001b[32m2025-02-17 14:37:14.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3183 test 0.3723 metric ['0.8656']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:14.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3629, current loss 0.3723.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:09<00:00,  1.88s/it]\n",
      "\u001b[32m2025-02-17 14:37:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:14.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:14.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143714\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:14.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143714/20250217-143714\u001b[0m\n",
      "\u001b[32m2025-02-17 14:37:14.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:20<00:00, 727.76it/s]\n",
      "\u001b[32m2025-02-17 14:37:35.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4901 test 0.4316 metric ['0.8438']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:21<00:00, 714.24it/s]\n",
      "\u001b[32m2025-02-17 14:37:57.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3811 test 0.4285 metric ['0.8477']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:22<00:00, 666.68it/s]\n",
      "\u001b[32m2025-02-17 14:38:20.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3537 test 0.3904 metric ['0.8542']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:22<00:00, 657.94it/s]\n",
      "\u001b[32m2025-02-17 14:38:44.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3381 test 0.4178 metric ['0.8523']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:38:44.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3904, current loss 0.4178.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:22<00:00, 658.20it/s]\n",
      "\u001b[32m2025-02-17 14:39:07.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3246 test 0.3888 metric ['0.8651']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:53<00:00, 22.66s/it]\n",
      "\u001b[32m2025-02-17 14:39:07.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:39:07.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:39:07.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_143907\u001b[0m\n",
      "\u001b[32m2025-02-17 14:39:07.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_143907/20250217-143907\u001b[0m\n",
      "\u001b[32m2025-02-17 14:39:07.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 709.35it/s]\n",
      "\u001b[32m2025-02-17 14:39:18.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4879 test 0.4024 metric ['0.8567']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:12<00:00, 604.88it/s]\n",
      "\u001b[32m2025-02-17 14:39:31.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3708 test 0.3928 metric ['0.8641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:11<00:00, 656.63it/s]\n",
      "\u001b[32m2025-02-17 14:39:43.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3367 test 0.3935 metric ['0.8582']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:39:43.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3928, current loss 0.3935.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:11<00:00, 633.05it/s]\n",
      "\u001b[32m2025-02-17 14:39:56.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3163 test 0.3564 metric ['0.8720']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:12<00:00, 591.21it/s]\n",
      "\u001b[32m2025-02-17 14:40:09.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3037 test 0.3606 metric ['0.8758']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:09.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3564, current loss 0.3606.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:01<00:00, 12.28s/it]\n",
      "\u001b[32m2025-02-17 14:40:09.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:09.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:09.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144009\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:09.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144009/20250217-144009\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:09.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:04<00:00, 780.87it/s]\n",
      "\u001b[32m2025-02-17 14:40:14.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4867 test 0.4609 metric ['0.8301']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 693.27it/s]\n",
      "\u001b[32m2025-02-17 14:40:20.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3645 test 0.3663 metric ['0.8644']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 571.22it/s]\n",
      "\u001b[32m2025-02-17 14:40:27.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3299 test 0.3840 metric ['0.8580']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:27.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3663, current loss 0.3840.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 636.50it/s]\n",
      "\u001b[32m2025-02-17 14:40:33.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3096 test 0.3409 metric ['0.8729']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 638.76it/s]\n",
      "\u001b[32m2025-02-17 14:40:39.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2916 test 0.3584 metric ['0.8683']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:39.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3409, current loss 0.3584.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:30<00:00,  6.07s/it]\n",
      "\u001b[32m2025-02-17 14:40:39.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:39.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:39.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144039\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:39.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144039/20250217-144039\u001b[0m\n",
      "\u001b[32m2025-02-17 14:40:39.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 571.15it/s]\n",
      "\u001b[32m2025-02-17 14:40:43.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5027 test 0.4540 metric ['0.8341']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 481.44it/s]\n",
      "\u001b[32m2025-02-17 14:40:47.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3693 test 0.3896 metric ['0.8592']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 485.76it/s]\n",
      "\u001b[32m2025-02-17 14:40:51.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3310 test 0.3703 metric ['0.8684']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 458.01it/s]\n",
      "\u001b[32m2025-02-17 14:40:56.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3101 test 0.3510 metric ['0.8731']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 456.22it/s]\n",
      "\u001b[32m2025-02-17 14:41:00.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2908 test 0.3608 metric ['0.8711']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:00.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3510, current loss 0.3608.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:20<00:00,  4.16s/it]\n",
      "\u001b[32m2025-02-17 14:41:00.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:00.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:00.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144100\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:00.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144100/20250217-144100\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:00.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 447.38it/s]\n",
      "\u001b[32m2025-02-17 14:41:02.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5316 test 0.4200 metric ['0.8458']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 410.15it/s]\n",
      "\u001b[32m2025-02-17 14:41:05.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3752 test 0.4001 metric ['0.8539']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 378.49it/s]\n",
      "\u001b[32m2025-02-17 14:41:08.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3390 test 0.3786 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 362.76it/s]\n",
      "\u001b[32m2025-02-17 14:41:10.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3155 test 0.3711 metric ['0.8598']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 352.91it/s]\n",
      "\u001b[32m2025-02-17 14:41:13.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2966 test 0.3470 metric ['0.8757']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.65s/it]\n",
      "\u001b[32m2025-02-17 14:41:13.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:13.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:13.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144113\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:13.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144113/20250217-144113\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:13.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 264.84it/s]\n",
      "\u001b[32m2025-02-17 14:41:15.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5793 test 0.4711 metric ['0.8318']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 289.24it/s]\n",
      "\u001b[32m2025-02-17 14:41:17.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3937 test 0.4041 metric ['0.8556']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 270.19it/s]\n",
      "\u001b[32m2025-02-17 14:41:19.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3504 test 0.3831 metric ['0.8610']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 269.28it/s]\n",
      "\u001b[32m2025-02-17 14:41:21.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3239 test 0.3632 metric ['0.8669']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 251.51it/s]\n",
      "\u001b[32m2025-02-17 14:41:23.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3045 test 0.3550 metric ['0.8724']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:09<00:00,  1.95s/it]\n",
      "\u001b[32m2025-02-17 14:41:23.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:23.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:23.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144123\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:23.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144123/20250217-144123\u001b[0m\n",
      "\u001b[32m2025-02-17 14:41:23.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:18<00:00, 832.55it/s]\n",
      "\u001b[32m2025-02-17 14:41:42.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4915 test 0.4282 metric ['0.8484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:18<00:00, 803.61it/s]\n",
      "\u001b[32m2025-02-17 14:42:01.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3777 test 0.4304 metric ['0.8475']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:42:01.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.4282, current loss 0.4304.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 752.10it/s]\n",
      "\u001b[32m2025-02-17 14:42:22.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3497 test 0.3889 metric ['0.8572']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 761.93it/s]\n",
      "\u001b[32m2025-02-17 14:42:42.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3277 test 0.4302 metric ['0.8592']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:42:42.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3889, current loss 0.4302.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:19<00:00, 766.88it/s]\n",
      "\u001b[32m2025-02-17 14:43:02.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3192 test 0.3853 metric ['0.8667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:39<00:00, 19.83s/it]\n",
      "\u001b[32m2025-02-17 14:43:02.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:02.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144302\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144302/20250217-144302\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:02.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 738.86it/s]\n",
      "\u001b[32m2025-02-17 14:43:13.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4918 test 0.4505 metric ['0.8431']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 685.87it/s]\n",
      "\u001b[32m2025-02-17 14:43:24.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3664 test 0.3778 metric ['0.8640']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 736.17it/s]\n",
      "\u001b[32m2025-02-17 14:43:35.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3349 test 0.3704 metric ['0.8674']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 692.96it/s]\n",
      "\u001b[32m2025-02-17 14:43:46.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3158 test 0.3907 metric ['0.8609']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:46.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3704, current loss 0.3907.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 714.22it/s]\n",
      "\u001b[32m2025-02-17 14:43:57.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2993 test 0.3565 metric ['0.8716']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:54<00:00, 10.97s/it]\n",
      "\u001b[32m2025-02-17 14:43:57.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:57.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:57.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144357\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:57.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144357/20250217-144357\u001b[0m\n",
      "\u001b[32m2025-02-17 14:43:57.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 651.48it/s]\n",
      "\u001b[32m2025-02-17 14:44:03.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4950 test 0.4347 metric ['0.8440']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 604.59it/s]\n",
      "\u001b[32m2025-02-17 14:44:10.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3668 test 0.3842 metric ['0.8647']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 558.44it/s]\n",
      "\u001b[32m2025-02-17 14:44:17.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3342 test 0.3821 metric ['0.8581']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 548.68it/s]\n",
      "\u001b[32m2025-02-17 14:44:24.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3086 test 0.4140 metric ['0.8483']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:24.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3821, current loss 0.4140.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 568.72it/s]\n",
      "\u001b[32m2025-02-17 14:44:31.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2939 test 0.3523 metric ['0.8748']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:34<00:00,  6.82s/it]\n",
      "\u001b[32m2025-02-17 14:44:31.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:31.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:31.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144431\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:31.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144431/20250217-144431\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:31.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 570.18it/s]\n",
      "\u001b[32m2025-02-17 14:44:35.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5175 test 0.4584 metric ['0.8333']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 515.34it/s]\n",
      "\u001b[32m2025-02-17 14:44:39.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3718 test 0.4149 metric ['0.8488']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 494.29it/s]\n",
      "\u001b[32m2025-02-17 14:44:43.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3341 test 0.4028 metric ['0.8514']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 466.29it/s]\n",
      "\u001b[32m2025-02-17 14:44:47.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3088 test 0.3721 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 417.63it/s]\n",
      "\u001b[32m2025-02-17 14:44:52.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2925 test 0.3641 metric ['0.8713']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:20<00:00,  4.19s/it]\n",
      "\u001b[32m2025-02-17 14:44:52.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:52.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:52.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144452\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:52.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144452/20250217-144452\u001b[0m\n",
      "\u001b[32m2025-02-17 14:44:52.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 434.48it/s]\n",
      "\u001b[32m2025-02-17 14:44:55.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5347 test 0.4167 metric ['0.8509']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 408.23it/s]\n",
      "\u001b[32m2025-02-17 14:44:57.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3787 test 0.3941 metric ['0.8532']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 379.42it/s]\n",
      "\u001b[32m2025-02-17 14:45:00.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3372 test 0.3807 metric ['0.8605']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 359.24it/s]\n",
      "\u001b[32m2025-02-17 14:45:03.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3144 test 0.3747 metric ['0.8660']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 329.24it/s]\n",
      "\u001b[32m2025-02-17 14:45:06.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2961 test 0.3342 metric ['0.8796']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:13<00:00,  2.72s/it]\n",
      "\u001b[32m2025-02-17 14:45:06.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:06.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:06.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144506\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:06.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144506/20250217-144506\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:06.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 243.19it/s]\n",
      "\u001b[32m2025-02-17 14:45:08.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5870 test 0.4693 metric ['0.8304']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 251.81it/s]\n",
      "\u001b[32m2025-02-17 14:45:10.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3952 test 0.4107 metric ['0.8523']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 251.78it/s]\n",
      "\u001b[32m2025-02-17 14:45:12.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3503 test 0.3683 metric ['0.8672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 243.24it/s]\n",
      "\u001b[32m2025-02-17 14:45:14.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3265 test 0.3539 metric ['0.8737']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 254.76it/s]\n",
      "\u001b[32m2025-02-17 14:45:16.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3026 test 0.3548 metric ['0.8712']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:16.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3539, current loss 0.3548.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:10<00:00,  2.09s/it]\n",
      "\u001b[32m2025-02-17 14:45:16.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:16.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:16.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144516\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:16.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144516/20250217-144516\u001b[0m\n",
      "\u001b[32m2025-02-17 14:45:16.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:22<00:00, 660.53it/s]\n",
      "\u001b[32m2025-02-17 14:45:40.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4922 test 0.4307 metric ['0.8389']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:23<00:00, 651.58it/s]\n",
      "\u001b[32m2025-02-17 14:46:03.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3777 test 0.3933 metric ['0.8574']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:24<00:00, 612.94it/s]\n",
      "\u001b[32m2025-02-17 14:46:29.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3492 test 0.4150 metric ['0.8531']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:46:29.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3933, current loss 0.4150.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:25<00:00, 583.66it/s]\n",
      "\u001b[32m2025-02-17 14:46:55.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3339 test 0.3847 metric ['0.8647']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:26<00:00, 567.99it/s]\n",
      "\u001b[32m2025-02-17 14:47:22.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3213 test 0.3748 metric ['0.8696']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [02:05<00:00, 25.15s/it]\n",
      "\u001b[32m2025-02-17 14:47:22.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:47:22.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:47:22.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144722\u001b[0m\n",
      "\u001b[32m2025-02-17 14:47:22.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144722/20250217-144722\u001b[0m\n",
      "\u001b[32m2025-02-17 14:47:22.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:11<00:00, 639.40it/s]\n",
      "\u001b[32m2025-02-17 14:47:34.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4848 test 0.4466 metric ['0.8361']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:13<00:00, 556.69it/s]\n",
      "\u001b[32m2025-02-17 14:47:48.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3670 test 0.3817 metric ['0.8601']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:12<00:00, 592.97it/s]\n",
      "\u001b[32m2025-02-17 14:48:01.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3350 test 0.3794 metric ['0.8706']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:13<00:00, 552.65it/s]\n",
      "\u001b[32m2025-02-17 14:48:15.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3130 test 0.3465 metric ['0.8743']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:13<00:00, 558.24it/s]\n",
      "\u001b[32m2025-02-17 14:48:29.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3009 test 0.3644 metric ['0.8727']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:29.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3465, current loss 0.3644.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:07<00:00, 13.43s/it]\n",
      "\u001b[32m2025-02-17 14:48:29.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:29.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:29.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144829\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:29.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144829/20250217-144829\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:29.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:05<00:00, 647.24it/s]\n",
      "\u001b[32m2025-02-17 14:48:35.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4827 test 0.4417 metric ['0.8372']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 569.46it/s]\n",
      "\u001b[32m2025-02-17 14:48:42.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3635 test 0.3860 metric ['0.8573']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:07<00:00, 509.93it/s]\n",
      "\u001b[32m2025-02-17 14:48:50.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3261 test 0.3949 metric ['0.8596']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:48:50.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3860, current loss 0.3949.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:07<00:00, 523.47it/s]\n",
      "\u001b[32m2025-02-17 14:48:58.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3061 test 0.3366 metric ['0.8782']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 537.89it/s]\n",
      "\u001b[32m2025-02-17 14:49:05.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2913 test 0.3607 metric ['0.8694']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:05.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3366, current loss 0.3607.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:35<00:00,  7.17s/it]\n",
      "\u001b[32m2025-02-17 14:49:05.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:05.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:05.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144905\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:05.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144905/20250217-144905\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:05.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 549.92it/s]\n",
      "\u001b[32m2025-02-17 14:49:09.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4944 test 0.4062 metric ['0.8552']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 489.89it/s]\n",
      "\u001b[32m2025-02-17 14:49:13.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3633 test 0.3718 metric ['0.8660']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 453.23it/s]\n",
      "\u001b[32m2025-02-17 14:49:17.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3280 test 0.3672 metric ['0.8652']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 427.09it/s]\n",
      "\u001b[32m2025-02-17 14:49:22.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3027 test 0.3551 metric ['0.8700']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 401.41it/s]\n",
      "\u001b[32m2025-02-17 14:49:27.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2866 test 0.3388 metric ['0.8790']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:22<00:00,  4.41s/it]\n",
      "\u001b[32m2025-02-17 14:49:27.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:27.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:27.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144927\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:27.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144927/20250217-144927\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:27.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 395.67it/s]\n",
      "\u001b[32m2025-02-17 14:49:30.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5221 test 0.4327 metric ['0.8423']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 372.98it/s]\n",
      "\u001b[32m2025-02-17 14:49:33.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3709 test 0.4030 metric ['0.8529']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 351.98it/s]\n",
      "\u001b[32m2025-02-17 14:49:35.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3341 test 0.3629 metric ['0.8661']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 322.82it/s]\n",
      "\u001b[32m2025-02-17 14:49:39.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3081 test 0.3471 metric ['0.8800']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 321.07it/s]\n",
      "\u001b[32m2025-02-17 14:49:42.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2908 test 0.3588 metric ['0.8708']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:42.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3471, current loss 0.3588.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:14<00:00,  2.91s/it]\n",
      "\u001b[32m2025-02-17 14:49:42.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:42.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:42.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144942\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:42.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144942/20250217-144942\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:42.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 239.91it/s]\n",
      "\u001b[32m2025-02-17 14:49:44.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5696 test 0.4605 metric ['0.8316']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 240.17it/s]\n",
      "\u001b[32m2025-02-17 14:49:46.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3879 test 0.3935 metric ['0.8576']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 254.30it/s]\n",
      "\u001b[32m2025-02-17 14:49:48.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3446 test 0.3739 metric ['0.8664']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 231.09it/s]\n",
      "\u001b[32m2025-02-17 14:49:50.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3178 test 0.3683 metric ['0.8702']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 225.83it/s]\n",
      "\u001b[32m2025-02-17 14:49:53.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3009 test 0.3565 metric ['0.8710']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:10<00:00,  2.18s/it]\n",
      "\u001b[32m2025-02-17 14:49:53.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:53.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:53.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_144953\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:53.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_144953/20250217-144953\u001b[0m\n",
      "\u001b[32m2025-02-17 14:49:53.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:26<00:00, 576.72it/s]\n",
      "\u001b[32m2025-02-17 14:50:19.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4914 test 0.4466 metric ['0.8400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:28<00:00, 528.31it/s]\n",
      "\u001b[32m2025-02-17 14:50:48.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3859 test 0.4132 metric ['0.8487']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:29<00:00, 513.62it/s]\n",
      "\u001b[32m2025-02-17 14:51:18.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3554 test 0.3703 metric ['0.8642']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:30<00:00, 492.90it/s]\n",
      "\u001b[32m2025-02-17 14:51:50.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3391 test 0.4103 metric ['0.8541']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:51:50.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3703, current loss 0.4103.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 15000/15000 [00:31<00:00, 482.57it/s]\n",
      "\u001b[32m2025-02-17 14:52:21.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3241 test 0.3898 metric ['0.8677']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:52:21.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3703, current loss 0.3898.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [02:28<00:00, 29.71s/it]\n",
      "\u001b[32m2025-02-17 14:52:21.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:52:21.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:52:21.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_145221\u001b[0m\n",
      "\u001b[32m2025-02-17 14:52:21.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_145221/20250217-145221\u001b[0m\n",
      "\u001b[32m2025-02-17 14:52:21.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:10<00:00, 709.78it/s]\n",
      "\u001b[32m2025-02-17 14:52:32.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4841 test 0.4286 metric ['0.8475']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:12<00:00, 603.32it/s]\n",
      "\u001b[32m2025-02-17 14:52:45.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3654 test 0.3814 metric ['0.8577']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:12<00:00, 595.60it/s]\n",
      "\u001b[32m2025-02-17 14:52:58.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3336 test 0.3543 metric ['0.8723']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:14<00:00, 527.36it/s]\n",
      "\u001b[32m2025-02-17 14:53:13.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3170 test 0.3893 metric ['0.8646']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:13.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3543, current loss 0.3893.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 7500/7500 [00:13<00:00, 551.58it/s]\n",
      "\u001b[32m2025-02-17 14:53:27.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3027 test 0.3689 metric ['0.8651']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:27.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3543, current loss 0.3689.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:05<00:00, 13.13s/it]\n",
      "\u001b[32m2025-02-17 14:53:27.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:27.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:27.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_145327\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:27.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_145327/20250217-145327\u001b[0m\n",
      "\u001b[32m2025-02-17 14:53:27.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:06<00:00, 582.72it/s]\n",
      "\u001b[32m2025-02-17 14:53:34.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4810 test 0.4428 metric ['0.8343']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:07<00:00, 516.41it/s]\n",
      "\u001b[32m2025-02-17 14:53:41.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3626 test 0.3983 metric ['0.8605']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:08<00:00, 443.05it/s]\n",
      "\u001b[32m2025-02-17 14:53:50.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3291 test 0.3754 metric ['0.8636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:07<00:00, 469.39it/s]\n",
      "\u001b[32m2025-02-17 14:53:59.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3049 test 0.3587 metric ['0.8723']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3750/3750 [00:07<00:00, 502.71it/s]\n",
      "\u001b[32m2025-02-17 14:54:07.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2899 test 0.3504 metric ['0.8725']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:39<00:00,  7.94s/it]\n",
      "\u001b[32m2025-02-17 14:54:07.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:07.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:07.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_145407\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:07.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_145407/20250217-145407\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:07.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:03<00:00, 513.18it/s]\n",
      "\u001b[32m2025-02-17 14:54:11.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.4891 test 0.3958 metric ['0.8584']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 446.04it/s]\n",
      "\u001b[32m2025-02-17 14:54:15.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3607 test 0.3949 metric ['0.8613']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 412.36it/s]\n",
      "\u001b[32m2025-02-17 14:54:20.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3250 test 0.3604 metric ['0.8683']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:04<00:00, 391.65it/s]\n",
      "\u001b[32m2025-02-17 14:54:25.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3038 test 0.3432 metric ['0.8795']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 1875/1875 [00:05<00:00, 357.84it/s]\n",
      "\u001b[32m2025-02-17 14:54:31.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2845 test 0.3427 metric ['0.8780']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:24<00:00,  4.83s/it]\n",
      "\u001b[32m2025-02-17 14:54:31.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:31.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:31.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_145431\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:31.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_145431/20250217-145431\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:31.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 357.31it/s]\n",
      "\u001b[32m2025-02-17 14:54:34.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5090 test 0.4265 metric ['0.8417']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:02<00:00, 338.96it/s]\n",
      "\u001b[32m2025-02-17 14:54:37.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3662 test 0.3735 metric ['0.8652']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 287.96it/s]\n",
      "\u001b[32m2025-02-17 14:54:40.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3293 test 0.3576 metric ['0.8734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 284.03it/s]\n",
      "\u001b[32m2025-02-17 14:54:44.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3057 test 0.3477 metric ['0.8751']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 262.43it/s]\n",
      "\u001b[32m2025-02-17 14:54:48.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2869 test 0.3452 metric ['0.8774']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:16<00:00,  3.36s/it]\n",
      "\u001b[32m2025-02-17 14:54:48.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /home/sarmad/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:48.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /home/sarmad/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:48.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/sarmad/Documents/code/upperkaam/notebooks_review/Deliverable_Part_1/notebooks/1_pytorch_intro/modellogs/experiment_20250217_145448\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:48.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellogs/experiment_20250217_145448/20250217-145448\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:48.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 238.01it/s]\n",
      "\u001b[32m2025-02-17 14:54:50.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5560 test 0.4433 metric ['0.8425']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 230.86it/s]\n",
      "\u001b[32m2025-02-17 14:54:52.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3815 test 0.3784 metric ['0.8664']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 237.76it/s]\n",
      "\u001b[32m2025-02-17 14:54:54.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3388 test 0.3876 metric ['0.8642']\u001b[0m\n",
      "\u001b[32m2025-02-17 14:54:54.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3784, current loss 0.3876.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 215.81it/s]\n",
      "\u001b[32m2025-02-17 14:54:57.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3132 test 0.3576 metric ['0.8721']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:02<00:00, 196.85it/s]\n",
      "\u001b[32m2025-02-17 14:54:59.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2979 test 0.3340 metric ['0.8789']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:11<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import gin\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Experiment loop\n",
    "for unit1 in units_values:\n",
    "    for unit2 in units_values:\n",
    "        for batch_size in batch_sizes:\n",
    "            # Create datastreamers with current batchsize\n",
    "            streamers = fashionfactory.create_datastreamer(batchsize=batch_size, preprocessor=preprocessor)\n",
    "            train = streamers[\"train\"]\n",
    "            valid = streamers[\"valid\"]\n",
    "            trainstreamer = train.stream()\n",
    "            validstreamer = valid.stream()\n",
    "\n",
    "            # Bind hyperparameters to the gin configuration\n",
    "            gin.bind_parameter(\"NeuralNetwork.units1\", unit1)\n",
    "            gin.bind_parameter(\"NeuralNetwork.units2\", unit2)\n",
    "\n",
    "            # Initialize model\n",
    "            model = imagemodels.NeuralNetwork()\n",
    "\n",
    "            \"\"\"\n",
    "            To store experiments with timesamps we will dataetime library to get the current time to store \n",
    "            the model at that timestamps.\n",
    "            \"\"\"\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            logdir = f\"modellogs/experiment_{timestamp}\"\n",
    "\n",
    "            # Define trainer settings\n",
    "            settings = TrainerSettings(\n",
    "                epochs=5,\n",
    "                metrics=[accuracy],\n",
    "                logdir=logdir,\n",
    "                train_steps=len(train),\n",
    "                valid_steps=len(valid),\n",
    "                reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    "            )\n",
    "\n",
    "            # Similar to previous example initialize trainer\n",
    "            # this will helps us to train and log the values in the logdir\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                settings=settings,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                traindataloader=trainstreamer,\n",
    "                validdataloader=validstreamer,\n",
    "                scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            trainer.loop()\n",
    "\n",
    "            # Save results for plotting heat-map\n",
    "            import os\n",
    "            # This will get the path file where we store the tensorboard values.\n",
    "            dirs = [os.path.join(logdir, d) for d in os.listdir(logdir) if os.path.isdir(os.path.join(logdir, d))]\n",
    "            \n",
    "            # `load_tensorboard_data` function is defined earlier, which will load the values from the stored tensorboard\n",
    "            metrics = load_tensorboard_data(dirs[0])\n",
    "            final_accuracy = metrics[-1]\n",
    "            results[units.index(unit1), batch_sizes.index(batch_size)] = final_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "The above experiments are run for 5 epochs for each combination of the `unit1`, `unit2`, and `batch_size`. As you can see the results in the above section, the final accuracy range from 85% to 88% depending on the values provided for each variable. We will next plot the heatmap for these values to visually see the relation between them.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "After running multiple experiments, we need a clear way to analyze performance trends. A heatmap helps compare accuracy across different units and batch sizes. We are plotting a heatmap using `seaborn` library.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot heatmap for units vs. batchsize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(results, annot=True, fmt=\".2f\", xticklabels=batch_sizes, yticklabels=units, cmap=\"viridis\")\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Units\")\n",
    "plt.title(\"Accuracy: Units vs. Batch Size\")\n",
    "plt.savefig(\"units_vs_batchsize_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86769998 0.86510003 0.8725     0.87800479 0.87740386 0.87890625]\n",
      " [0.85229999 0.87199998 0.86830002 0.87109375 0.87570113 0.87239581]\n",
      " [0.8682     0.8448     0.86220002 0.86207932 0.87770432 0.86969149]]\n"
     ]
    }
   ],
   "source": [
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "In this heatmap, we are comparing accuracy across different configurations of units (neurons per layer) and batch sizes to see how they impact model performance. The x-axis represents batch size (ranging from 4 to 128), while the y-axis represents the number of units (64, 128, and 256). The brighter colors indicate higher accuracy, and we can see that larger batch sizes (64 and 128) consistently lead to better accuracy, with the highest at 256 units and batch sizes of 64 or 128 (0.88 accuracy). While increasing the number of units improves performance slightly, its impact is not as significant as batch size, which suggests that for better model accuracy, optimizing batch size is more effective than simply adding more neurons.\n",
    "</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
